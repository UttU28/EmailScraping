{
    "0_only W2, Microsoft Azure Cloud Systems Architect": "priyanka verma,\nTriwave Solutions Inc\npriyanka@triwavesolutions.com\nReply to: priyanka@triwavesolutions.com\nPosition Title*Cloud Systems Architect (7/12)Position ResponsibilitiesJob Title: Cloud and System ArchitectJob Location: Tallahassee, FL (hybrid)Job Duration: 12-month contractJob Overview: Cloud and Systems Architect to play a key role in assisting IT in the oversight, management, and execution of cloud services and platforms to support infrastructure, applications, data, and other business needs.Design, upgrade, administer, test, and modify the virtual desktop infrastructure environment.Assist in ongoing modernization and migration efforts for applications, data, and infrastructure.Oversight and management of Microsoft 365 environments.Oversight and management of other Microsoft platforms and/or environments.Oversight and management of identity platforms.Oversight and management of a multi-cloud environment.Architect, design, facilitate, lead, coordinate, and direct technology initiatives on multiple fronts across a variety of disparate areas within the organization. This could include Infrastructure administration, application development, data management & analytics, cybersecurity, external hosting, identity and access management, infrastructure, network, security hardening, privacy, and compliance.Job Duties:Build and manage relationships in a matrixed environment.Recommend and assist with the building and hosting of complex application solutions.Understand, deploy, and manage Microsoft Azure and/or other cloud services.Understand, deploy, and manage Microsoft Power Platform.Find opportunities to refactor solutions to obtain better performance, cost, and efficiency.Enhance infrastructure, application, and system monitoring solutions to prioritize system uptime.Review, advise, and design based on risks, costs, benefits and impact on the enterprise business process and goals.Automate processes wherever possible.Create and manage Azure DevOps projects, git repositories, and pipelines.Troubleshoot issues brought forth by developers and other architects.Present to your peers on findings of new technologies, enterprise-wide issues, and enhancements you have made to better the mission.Required Experience: 2 \u2013 3 years of strong professional experience as a Microsoft Azure cloud systems architect is required.5 - 8 years of professional experience in information systems engineering or another related field is required.2 - 3 years of experience in Enterprise Architecture is required.Strong analytical skills to determine an organization's needs, develop strategies to meet those needs, and evaluate effectiveness.Ability to categorize work, set priorities, and determine short and/or long-term goals and strategies to achieve them.Ability to troubleshoot and diagnose problems effectively regardless of technology platform.Able to easily convey knowledge to others.Proficiency in working in a fast-paced, complex, and dynamic business environment.In-depth knowledge of Microsoft Azure Services.In-depth knowledge of Microsoft Server products.In-depth knowledge of Linux (Redhat and Ubuntu).Strong grasp of IT infrastructure and application development technology and architectures.Knowledge of assessment and analytical process and practices.Skill in strategic planning.Skill in researching, compiling, and analyzing data to report findings and develop improvement solutions.Skill in system administration and hosting across a wide range of solutionsAbility to research, identify, and implement innovative solutions.Ability to communicate effectively; both verbally and written.Ability to establish and maintain effective working relationships.Ability to work independently and as a team.Preferred Experience:2 \u2013 3 years of experience with other cloud providers, such as AWS or GCP is highly desired.5 years of professional experience supporting middleware such as API Management, IT Service Automation tools, and batch job services is highly desired.2 - 3 years of professional experience in administration of Microsoft software is highly desired.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "1_JD||AWS Engineer||Culver City CA": "vikas kumar,\nsynkriom\nvikas.kumar@synkriom.com\nReply to: vikas.kumar@synkriom.com\nRole name: AWS EngineerRole Description:AWS Cloud Enablement EngineerCompetencies:Digital : Amazon Web Service(AWS) Cloud ComputingExperience (Years):8-10Essential Skills:AWS Cloud Enablement EngineerDesirable Skills:AWS Cloud Enablement Engineer Keywords:AWS Cloud Enablement Engineer\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "2_DevOps Architect :: Remote": "Ekta Chaudhary,\nEpeople Technologies\nekta@epeopletech.com\nReply to: ekta@epeopletech.com\nTerraform Template creation Terraform module write upAWS Resources including Gateway, Lambda, Authentication patternHelm templatePython or Shell scripting, Bash scriptingPython developmentGithub, Github action includes Scans like Sonar, AppSec Branching strategyGitOpsPython API developmentExperience in DevOps Architecture design and strategy.how to deploy same authentication in Lambda and EKSServer less authentication services\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "3_Job Opportunity for Salesforce Commerce Cloud Technical Lead": "Gunadeep,\nAvance Consulting\ngunadeep.c@avanceservices.com\nReply to: gunadeep.c@avanceservices.com\nHello, Hope you are doing well...!This is GUNADEEP from AVANCE CONSULING, and I have a new job opening for you. Please have a look at the below job description, if interested please share your updated resume or feel free to contact me.Job Description:Title: Salesforce Commerce Cloud Technical Lead roleDuration: ContractLocation: RemotePlease find the JD below:8 to 10 years of hands-on development experienceMust understand eCommerce architecture, product, order, and inventory flows to create detailed designs, architectural documents, and develop solutions.Be able to support the full code review and release management for SFCC.Strong background in SFCC and SF OMS experience with eCommerce/Digital environment, Batch File Scripting, SQL, Java knowledge Should have worked on projects supporting SFCC implementation.Used DevOps such as Copado, Git, Flossum, etc.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "4_Very Urgent Job Opportunity of AWS LEAD (TECHNICAL LEAD) at Location- San Antonio, TX (Onsite) is shared with you": "Raghwendra Rao,\nIDC Technologies\nraghwendra.rao@idctechnologies.com\nReply to: raghwendra.rao@idctechnologies.com\nGreetings! This is Raghwendra from IDC Technologies, and I am writing to you regarding an excellent job opportunity that I have with one of IDC\u2019s premier clients in San Antonio, TX (Onsite). I found your resume during my search for qualified candidates on the internet and would like to know if you would be interested in pursuing this opportunity. Please share your updated resume if interested. Job Title: AWS LEAD (TECHNICAL LEAD)Position Type: CTH Location: San Antonio, TX (Oniste)Min. Exp- 12 Years Mandatory Skillset: AWS Architecture, AWS Services-Lambda Functions, AWS EC2, AWS S3Bucket, AWS EKS, RDS, SQS, Dynamo DB, Terraform SNS/ SQS, Java/J2EE, SOA, API Integration, Docker/Container/ Kubernetes, IAASOverview:Looking for talented cloud Developer (Lead) responsible for developing design and architecture to support cross domain business capabilities. Candidate will focus on the intentional architecture and provide mentorship on emergent architecture to the technical teams. Candidate will have hands-on experience in cloud architectures (SaaS, PaaS, IaaS) and deep interest and experience in broad enterprise platforms and cloud patterns. Job Description:Participate in producing conceptual, solution and component-level architectures and associated artifacts. Develop cross domain business requirements reference architecture for transition and target state and contribute to the cloud related patterns and implementations. Develop common components for shared business capabilities with Standards and best practices. Develop the transition architecture using services offered by AWS and private cloud.Migrate legacy applications to AWS and private cloud. Hands on experience with AWS cloud networking including VPCs, Subnets, Security Groups, ACLs, Transit Gateways, ALB/NLB, Route53, ACM, API Gateway and related technologies.Understanding of networking processing, protocols, and standards - TCP/IP, UDP, DNS, HTTPHands on experience with security mechanisms including mTLS, x509, OpenID Connect, JWT/JWE, OAuth2, PEP/PDP, SAML, WS-Security, Basic Auth and ABAC/RBAC based policies.Hands on \u201ccode first\u201d development of cloud configuration and components from the ground up using tools like Gitlab and TerraformStrong hands-on experience in one or more development languages including Java, python, Golang.Experience with Open Trace, AWS Cloud Watch, DataDog, Prometheus, ELK, Grafana, Hystrix,, App Dynamics, NetCool and other tools to ensure the cloud is operating as expected.Hands on experience with continuous delivery (CD) tooling including Jenkins, GitLab, Travis CI, GoCD and others.Hands on experience with Containers including tools like Docker, Kubernetes, ECS/ECR, and other related technologies and tools.Experience in explaining complex technology decisions and developing high trust relationships with stakeholders. Ability to develop target state architecture using services offered by AWS and private cloud and vision to develop the transition architecture. Ability to design patterns for moving legacy applications to AWS and private cloud. Hand on experience with common architecture patterns (microservices, event-driven, REST, NO SQL databases, Caches, etc.) and services offered by AWS (S3, EKS, Lambda, RDS, elastic search, etc.) Hands on experience addressing operational and non-functional concerns (e.g. scalability, performance, maintainability, load distribution, resilience and recovery, etc.) Experience with SAFe framework or other similar agile frameworks. Experience with Java, Kafka, Spring, Redis, Kubernetes, OpenShift and others. Guidewire experience is big plus.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "5_Hiring || Cloud Developer || Atlanta, GA Need a local candidateHybrid": "sakthivel,\nERPMark\nsakthivel@erpmark.com\nReply to: sakthivel@erpmark.com\nRole :Cloud DeveloperLocation : Atlanta, GA Need a local candidate HybridDuration : Long Term Note : Have to F2F interview JD: Strong AWS development with Python exp -Lambda, S3, Athena,Glue, DynamoDB, Event bridge\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "6_AWS Cloud Enablement Engineer": "Pradeep,\nScalable Systems\npradeep.sharma@scalable-systems.com\nReply to: pradeep.sharma@scalable-systems.com\nHi,Greetings of the day! I have an urgent requirement below, please go through JD and let me know if you are comfortable or have any profile. Kindly revert me back with your updated resume as well. Job Title: AWS Cloud Enablement Engineer Location: Culver City, CA (Work from Office)Duration: Long Term Contract Key Responsibilities:AWS Cloud Enablement EngineerAmazon Web Service(AWS)Cloud Computing Thanks & Regards, Pradeep SharmaEmail: pradeep.sharma@scalable-systems.com\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "7_Senior DevOps Engineer": "Pallavi,\nnss\nrec1@nityainc.com\nReply to: rec1@nityainc.com\nLoopNet - Senior DevOps EngineerJob Overview CoStar Group (NASDAQ: CSGP) is a leading global provider of commercial and residential real estate information, analytics, and online marketplaces. Included in the S&P 500 Index and the NASDAQ 100, CoStar Group is on a mission to digitize the world's real estate, empowering all people to discover properties, insights and connections that improve their businesses and lives. We have been living and breathing the world of real estate information and online marketplaces for over 35 years, giving us the perspective to create truly unique and valuable offerings to our customers. We've continually refined, transformed and perfected our approach to our business, creating a language that has become standard in our industry, for our customers, and even our competitors. We continue that effort today and are always working to improve and drive innovation. This is how we deliver for our customers, our employees, and investors. By equipping the brightest minds with the best resources available, we provide an invaluable edge in real estate. We are currently seeking an accomplished Senior DevOps Engineer to join our team, while supporting our multiple software products and brands across the organization, such as LoopNet , Apartments.com , Homes.com , and Ten-X .This position is located in Irvine and offers 2 days remote per week. ResponsibilitiesGrow the team's experiences and skillset through knowledge sharing and by having proactive and team-centered attitude.Automate and leverage DevOps principles, always striving for operational excellence with infrastructure-as-code mentality.Utilize cutting-edge technology to improve our services and processes.Manage enterprise level web applications.Collaborate with development and operations team to design and build scalable and secure infrastructure.Practice continuous integration/continuous delivery (CI/CD) using latest DevOps tools and innovative methods.Ensure the health and uptime of critical systems and applications with pro-active monitoring and metrics analysis.Strong troubleshooting skills (application, network, systems, infrastructure) with ability to multi-task and context switch.Good communication skills, expresses oneself clearly both verbally and in writing.Participate in a weekly on-call rotation once on-boarded.Basic QualificationsBachelor's Degree required from an accredited, not-for-profit university or college.A track record of commitment to prior employers.5+ years' experience with managing heavy web traffic sitesIaC (Terraform, Cloudformation)CI/CD (Azure DevOps)Kubernetes / EKSAWS (EC2, ALBs, S3, IAM, ASG, Lambda, Dynamo, Step Function, Elasticache, OpenSearch, etc.)Enterprise monitoring tools in areas of APM, system vitals, synthetics, and RUM (DataDog, AppDynamics, Prometheus, Icinga).Scripting language (PowerShell, Bash, YAML)Configuration management (e.g., Chef, Ansible)Experience with configuring CDN for performance caching and global traffic management.Preferred Qualifications And SkillsSome developer background with either Java, C#, Python, NodeJSFamiliar with load balancing technologies such as F5 LTMs, including management of VIPs, pools, nodes, iRule authoring, SSL offloading.SQL or No SQL databasesServer-less architecture methodologiesFamiliarity with PCI compliance and remediationAgile methodologies and working on short sprint cyclesWhat's in it for You When you join CoStar Group, you'll experience a collaborative and innovative culture working alongside the best and brightest to empower our people and customers to succeed.We offer you generous compensation and performance-based incentives. CoStar Group also invests in your professional and academic growth with internal training, tuition reimbursement, and an inter-office exchange program.Our benefits package includes (but is not limited to):Comprehensive healthcare coverage: Medical / Vision / Dental / Prescription DrugLife, legal, and supplementary insuranceVirtual and in person mental health counseling services for individuals and familyCommuter and parking benefits401(K) retirement plan with matching contributionsEmployee stock purchase planPaid time offTuition reimbursementOn-site fitness center and/or reimbursed fitness center membership costs (location dependent), with yoga studio, Pelotons, personal training, group exercise classesAccess to CoStar Group's Diversity, Equity, & Inclusion Employee Resource GroupsComplimentary gourmet coffee, tea, hot chocolate, fresh fruit, and other healthy snacksWe welcome all qualified candidates who are currently eligible to work full-time in the United States to apply. However, please note that CoStar Group is not able to provide visa sponsorship for this position.This position offers a base salary of $124,000 - $211,000, based on relevant skills and experience and includes a generous benefits plan.#LI-IZ1 #LI-HybridCoStar Group is an Equal Employment Opportunity Employer; we maintain a drug-free workplace and perform pre-employment substance abuse testingEmployers have access to artificial intelligence language tools (\u201cAI\u201d) that help generate and enhance job descriptions and AI may have been used to create this description. The position description has been reviewed for accuracy and Dice believes it to correctly reflect the job opportunity.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "8_Urgent Need: Azure Architect with EventHub, Snowflake and Cosmos DB, 100% Remote": "SAPNA,\nITECS\nsapna@itecsus.com\nReply to: sapna@itecsus.com\nUrgent need from Infocepts. Only US Citizens. Phone + Video interview.100% Remote from US location. Primary Skills: Technologies/Tools: Azure, EventHub, Snowflake, Cosmos DB, Managed Airflow, API Gateway & DBT Job Title: Azure Architect with EventHub, Snowflake and Cosmos DBWork Location: Onshore in USA \u2013 100% Remote Purpose of the Position: Purpose of this role is to design and build data architecture for a migration project. Major responsibilities under this role would be to create high level and low level design for data integration framework, translate the business requirements into technical prototypes, help developers in developing the data integration pipelines, perform peer reviews of the code, own the technical delivery of the DI part from inception to the deployment. Also own the technical consultation for existing or new clients during initial phase of any initiative and help in proposals and pre-sales initiatives. Must Have Technical Experience:At least 12 years of IT experience; Minimum 5 years of experience on AzureMust have minimum 5+ years of experience in implementing and managing Azure Cloud components.Expertise in Python and SQL best practicesExperience in data and analytics domainKnowledge of integrating Azure Active Directory with other servicesIn-depth experience of key Azure services for data integration, BI and processing services including but not limited to Azure HDInsight, Azure Databricks, Azure Portal, Log Analytics, Azure Data Factory, , Azure Search, Azure Functions, Azure Stream Analytics, Managed Airflow and Azure Event Hub.Experience in Azure cosmos DB over PostgreSQL, mongo dB and live streaming with Azure EventHub.Experience on Azure functions with Python language.Experience in migration of on-prem applications and data analytics workload to Azure cloud. Experience in designing Azure cloud architecture and operationalizing solutions around monitoring, alerting, logging etc.Working knowledge on Architecture design, Modelling, prototyping, and benchmarking of DataStore/ EDW solutions.Knowledge of variety of advanced architecture, tools, and concepts across all layers of modern distributed technology stack covering the big data ecosystem.Knowledge of Azure storage services such as Azure storage account, Azure Cosmos DB, Azure Time Series Insights, Redis Cache, SQL Databases, Table StorageExperience with programming languages such as PythonExperience in enabling DevOps automation for Azure with appropriate security and privacy considerations.Knowledge of configuring and provisioning networks and infrastructure in cloudGood to have knowledge of Big Data ecosystems such as Hadoop / Hive, HDFS, Spark, YARN and others.Good to have Snowflake, Scala, and Java experienceGood to have Technical Experience:Pre-sales experience will be an added advantage.Any BI experienceExperience in any other cloud technologies like AWS, ALI, GCP.Snowflake, DBT, Scala and JavaTechnologies/Tools: Azure, EventHub, Snowflake, Cosmos DB, Managed Airflow, API Gateway & DBTQualifications:Bachelor\u2019s degree in computer science, engineering, or related field (master\u2019s degree is a plus)Demonstrated continued learning through one or more technical certifications or related methods. ---------------------------------------------------------------------------------------------------------------------------Please follow the submission format table provided and ensure all required information is included with each submission with resume. Incomplete submissions will be disqualified. Candidate Legal Name (As per Documents) Summary Year of experience in each skillset: Email Address Phone Number Work Authorization Current Location For non-local, Relocation (Yes/No) Pay Rate Current working status Reason for change LinkedIn Profile Availability for Interview (Please provide 03 time slots) Availability for Joining the project\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "9_Devops Engineer": "Pallavi,\nnss\nrec1@nityainc.com\nReply to: rec1@nityainc.com\nThis company provides a global payments software offering that has grown consistently over the last decade. Great company with vertical growth opportunity!This Jobot Job is hosted by: Alex DickinsonAre you a fit? Easy Apply now by clicking the \"Apply Now\" button and sending us your resume.Salary: $120,000 - $165,000 per yearA bit about us:This company is a modern software product firm that services clients all across the US. They have a very mature and modern IT infrastructure posture. Their current team is looking for a Devops engineer functioning in a .NET environment with cloud experience.Why join us?Competitive Base Salary - $120-155kQuarterly bonus plan401k with matchGym reimbursementWFH optionsAccelerated Career Growth!Job DetailsBuilding, configuration, deployment, and management of high volume, highly available .Net applicationsWindows Server/IIS deployment, configuration, and administrationKubernetes (AKS) deployment, configuration, and administrationAzure DevOpsMonolithic architectureTerraformOctopus DeployGitPowershell abilitiesSolid understanding of core concepts: DNS, HTTP/HTTPS, Load-Balancing, TCP/IP routing and switchingInterested in hearing more? Easy Apply now by clicking the \"Apply Now\" button.Employers have access to artificial intelligence language tools (\u201cAI\u201d) that help generate and enhance job descriptions and AI may have been used to create this description. The position description has been reviewed for accuracy and Dice believes it to correctly reflect the job opportunity.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "10_urgent : DevOps engineer | GC EAD,H4 EAD,OPT EAD | Newport Beach, California": "Ramashankar,\nvyzeinc\nramashankar@vyzeinc.com\nReply to: ramashankar@vyzeinc.com\nJob Description -Please try to submit some genuine candidates, as we have previosly submitted some candiates who were fake and couldn't explain the skills mentioned in the resume.Need LinkedIn, DL and Visa with submissionTitle: DevOps engineerLocation: Newport Beach, CA (100% Onsite) Job Description: We need a DevOps engineer to assist developers in utilizing AI for processing unstructured data.This involves establishing a solution for the acquisition, movement, and ingestion of large volumes of unstructured data on a daily basis, and making this data available for AI processing.Skills, in priority order (from must-have to nice-to-have), include:DevOps that can code: 25% coding, 75% operationsPythonKubernetes (K8s), Airflow/Dagster/Airbyte, Argo Workflows, DatabricksInfrastructure as Code (IaC) - Terraform, Cloud Development Kit (CDK)Monitoring (Datadog, Splunk, PagerDuty) - managing a production systemEvent-based systems - KafkaAPIs, Layer 3/7 networking (Envoy)Application authentication (Okta)AI stack - OpenAI, Claude 3, Pinecone, SageMaker, Bedrock\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "11_AWS Cloud Enablement Engineer": "lavanya,\nKK associates\nlavanya@kksoftwareassociates.com\nReply to: lavanya@kksoftwareassociates.com\nWe are hiring hashtag#AWS_Cloud_Enablement_Engineer my Client interesting candidates please send resumes to lavanya@kksoftwareassociates.com or 614-379-0184Visa status: H1B/USC/GCPosition: AWS Cloud Enablement EngineerLocation: - WOODLAND HILLS, Culver City, CARole name:Product EngineerRole Description:AWS Cloud Enablement EngineerCompetencies:Digital : Amazon Web Service(AWS) Cloud ComputingExperience (Years):8-10Essential Skills:AWS Cloud Enablement Engineer\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "12_Immediate Req_AWS  Delphix Engineer": "Ben Clark,\nTech Talent Connect LLC\nben@techtalentconnect.com\nReply to: ben@techtalentconnect.com\nJob Title: AWS \u2013 Delphix EngineerLocation: San Antonio, TX (Day1 onsite, Hybrid)Duration: Long Term ContractRate: DOEResponsibilities:\u00b7 Creating, configuring, and maintaining Infrastructure on AWS Cloud services including Virtual Private Cloud VPC, EC2, RDS, S3, Route53, SNS, CloudFront, CloudWatch and IA.\u00b7 Migrating data from on-prem to Amazon Web Services cloud.\u00b7 Creating S3 buckets and folder management within it.\u00b7 Creating role-based policies to access AWS resources like S3 and other AWS services.\u00b7 Creating or Importing Volumes into AWS instances.\u00b7 Create and configure the Elastic Load balancers with Autoscaling groups.\u00b7 Create Alarms, events, logs on CloudWatch for monitoring and Cloud trail for logging events onto S3 to troubleshoot and record event history.\u00b7 Hands-on experience with databases MySQL, Oracle creating users, performing dump/restore, and taking automated snapshots.\u00b7 Exposure to Kubernetes clusters and managing the clusters using KOPS, Rancher.\u00b7 Experience in administration, engineering, and support of the Delphix platform \u2013 Mandatory.\u00b7 Onboard and manage VDB and dSources on Cloud and on prime premises \u2013 Mandatory.\u00b7 Strong scripting skills (e.g., Ansible, Shell scripting, Python, PowerShell) to develop and maintain automation of operational tasks.\u00b7 Good to have migration experience from on-prem to cloud.\u00b7 Formulate and implement Test Data Management plans.\u00b7 Proficiency in Delphix virtualization and Continuous Compliance.\u00b7 Perform in-place data masking with integrity.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "13_Urgent Need ||  Lead AWS Data Engineer || NYC NY 3 Days Hybrid from Day 1": "Neeraj Kumar,\nGlobal Applications Solution Pvt. Ltd\nneeraj.k@globalapplications.com\nReply to: neeraj.k@globalapplications.com\nRole: Lead AWS Data EngineerLocation: NYC NY 3 Days Hybrid from Day 1Job Summary:We are looking for an experienced Data Visualization and Migration Specialist with a strong background in AWS QuickSight, AWS Redshift, and Amazon Q. The ideal candidate will have a proven track record of working with data visualization tools, as well as extensive experience in data migration activities, specifically moving data from on-premises data stores to Amazon Redshift.Key Responsibilities:Design, develop, and maintain interactive dashboards and reports using AWS QuickSight.Leverage Amazon Q for natural language query capabilities to enhance data accessibility and usability.Manage and optimize AWS Redshift data warehouses, ensuring data integrity and performance.Conduct data migration from on-premises data stores to AWS Redshift, including planning, execution, and validation.Collaborate with cross-functional teams to understand business requirements and translate them into effective data visualizations and reporting solutions.Implement best practices for data management, data quality, and data governance.Troubleshoot and resolve issues related to data visualization and data migration.Provide training and support to end-users on using AWS QuickSight and Amazon Q.Stay updated with the latest trends and technologies in data visualization and data migration. Required Qualifications:Bachelor\u2019s degree in Computer Science, Information Systems, Data Science, or a related field.4-5 years of experience working with data visualization tools, specifically AWS QuickSight.Strong expertise in AWS Redshift, including data warehousing and performance optimization.Experience with Amazon Q for enhancing data accessibility.Proven experience with data migration activities, particularly moving data from on-premises data stores to Amazon Redshift.Proficient in SQL and database management.Strong analytical and problem-solving skills.Excellent communication and collaboration skills.Ability to work independently and manage multiple projects simultaneously. Preferred Qualifications:AWS Certification in any of the following: AWS Certified Solutions Architect, AWS Certified Data Analytics, AWS Certified Big Data.Experience with other data visualization tools like Tableau or Power BI.Knowledge of ETL processes and tools.Experience with scripting languages such as Python or R.Thanks Neeraj Kumar\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "14_AWS Cloud Engineer at remote": "Ujjwal,\nzealhire\nujjwal@zealhire.com\nReply to: ujjwal@zealhire.com\nHi RonHope you are doing well.Greetings from ZealHire Inc. Job Title: AWS Cloud EngineerLocation: remotePosition Type: ContractLooking for someone with Terraform, Python and AWS. This will be new development and support.Job Description:As an Engineer 2, candidate will be responsible for using candidate's technical knowledge of professional concepts to solve business problems.Client is looking for a talented individual who can serve as a subject matter expert in their area of focus and represent their department on complex assignments.Candidate will be responsible for evaluating elements of technology's effectiveness through requirements gathering, testing, research and investigation, and making recommendations for improvements resulting in increased quality and effectiveness.Candidate will be required to listen to and evaluate customer needs to determine and provide high-quality solutions that align with customer expectations.Client Mobility is seeking an Engineer 2 to support client\u2019s rapidly growing cloud enablement engine application and infrastructure portfolio.This role will automate configurations and templates for customer use to consume various AWS based services, manage AWS based services, measure and maintain reliability through instrumentation and monitoring, and interface with multiple development teams to provide services and support.Candidate will create and modify medium to complex Python and Terraform (HCL) code to enable our customers to more easily consume AWS services.Candidate will perform local development builds, being a primary contributor in code reviews, planning, testing, and coordinating of implementation activities.Participate in on-call rotation, which includes 24/7 support every two months of multiple production environments.Candidate will work with cloud vendors and external technical support on upgrades, problem resolution, and design issues.This is an exciting role in a fast-paced, collaborative team that strives to build and foster close working relationships with its application development customers.Required:2 plus years of software development experience.2 plus years of Python (boto3) and Terraform development experience.2 plus years of experience with core Amazon Web Services such as Route 53, EC2 (AMI, EBS, ELB, ASG), S3, CloudWatch, CloudFormation,ElasticBeanstalk, ElastiCache, IAM, VPC, RDS, DynamoDB, SQS, and SNS.Must be committed to incorporating security into all decisions and daily job responsibilities.Must be able to coach and mentor team members and customers.Experience with the design and build of web application cloud infrastructure.Experience in and demonstrable knowledge of Linux command line interface.Experiences with software design methodologies, information systems architecture, object-oriented design, and software design patterns.Excellent verbal and written communication skills.Excellent customer service skills.Familiarity with Agile/Scrum methodology.Ability to quickly triage problems, determine root cause and drive resolution.Familiarity with Software Development Lifecycle (SDLC)Knowledge of version control tools, such as git, BitBucket, and GitHubBachelor's degree in Computer Science, Computer Information Systems, Management Information Systems, or related field.Preferred:Experience in Jira, Confluence, Maven, and Jenkins.Experience with Linux package management (rpm, yum, dnf, etc).Experience with HTTP/Proxy servers (Apache, Nginx).Experience installing, configuring, and troubleshooting application platforms, with a preference for experience in working with Java web applicationplatforms (e.g., Tomcat, Spring Boot, etc.).Experience with monitoring and alerting tools such as Dynatrace, Cloudwatch or similar.Experience with log aggregation and management tools such as Splunk.Experience working with configuration management tools. Examples: Ansible.Systems performance tuning and load testing is a plus.Familiarity with large-scale systems and methodologies. Kind Regards, Ujjwal TiwariTechnical RecruiterZealHire Inc. Email: Ujjwal@zealhire.com14 Wall Street 20th Floor | New York, NY 10005www.zealhire.com\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "15_Need AWS Cloud Enablement Engineer": "ayush,\nScalable Systems\nayush.yadav@scalable-systems.com\nReply to: ayush.yadav@scalable-systems.com\nAWS Cloud Enablement EngineerCulver City, CAAbout the RoleDo you have a passion for cloud technology and enjoy helping others leverage its potential? We are seeking a highly motivated and experienced AWS Cloud Enablement Engineer to join our growing team in Culver City, CA. In this role, you will play a pivotal role in accelerating our organization's cloud adoption journey by empowering teams with the knowledge and skills they need to thrive in the AWS environment.Highlighted Skills and Keywords:AWS Certified Solutions Architect - Associate (or Professional)AWS Certified Cloud PractitionerStrong understanding of AWS services (EC2, S3, VPC, IAM, Lambda, etc.)Experience with cloud infrastructure design and deploymentExperience with infrastructure as code (IaC) tools (Terraform, CloudFormation)Excellent communication and collaboration skillsAbility to translate complex technical concepts into clear, actionable insights for non-technical audiencesProven ability to develop and deliver engaging technical training programsResponsibilities:Develop and implement a comprehensive cloud enablement strategy that aligns with our business objectives.Design and deliver engaging technical training programs on AWS fundamentals, best practices, and specific AWS services.Collaborate with engineering teams to identify cloud migration and optimization opportunities.Develop and maintain cloud infrastructure as code (IaC) templates for efficient and consistent deployments.Stay up-to-date on the latest AWS advancements and incorporate them into training programs and best practices.Develop and maintain documentation for cloud-related processes and procedures.Assist with troubleshooting and resolving cloud-related issues.Champion a culture of cloud adoption within the organization.Qualifications:Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent experience)8-10 years of experience in cloud computing or a related fieldProven experience in AWS cloud technologies (3+ years)Experience developing and delivering technical training programs (preferred)Familiarity with Agile methodologies (preferred)Experience with DevOps principles (a plus)\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "16_Need Locals || DevOps Engineer || Plano, TX- Day 1 Onsite": "Danish Mujeeb,\nHan Staffing\ndanish@hanstaffing.com\nReply to: danish@hanstaffing.com\nTitle: DevOps EngineerLocation: Plano, TX (Day 1 Onsite Need only local candidates)Long Term Contract Job Description:Excellent working experience in CI/CD to Setup CI/CD pipeline to achieve fully automated CI/CD process.Troubleshoot and rectify build pipeline issues.Schedule automated build and deployment and execute ad-hoc build request by AD teamHands-on knowledge of Bit-bucket, GIT commands and branching strategies.Other Skills:Knowledge of Unix commands required for day to day operations and troubleshooting.Scripting knowledge for automation.Knowledge of webapps (weblogic, Tomcat, Apache , IBM HTTP etc) and their troubleshooting.Working knowledge of schedulers ( control M, Autosys etc).SSL/TLS certificate management.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "17_Urgent Need : Devops Engineer :Plano, TX - Need Local": "Jagdeep Singh,\nHAN IT Staffing\njagdeep@hanstaffing.com\nReply to: jagdeep@hanstaffing.com\nTitle: DevOps EngineerLocation: Plano, TX (Day 1 Onsite Need only local candidates)Job Description:Excellent working experience in CI/CD to Setup CI/CD pipeline to achieve fully automated CI/CD process.Troubleshoot and rectify build pipeline issues.Schedule automated build and deployment and execute ad-hoc build request by AD teamHands-on knowledge of Bit-bucket, GIT commands and branching strategies.Other Skills:Knowledge of Unix commands required for day to day operations and troubleshooting.Scripting knowledge for automation.Knowledge of webapps (weblogic, Tomcat, Apache , IBM HTTP etc) and their troubleshooting.Working knowledge of schedulers ( control M, Autosys etc).SSL/TLS certificate management.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "18_Urgent hiring for Cloud Architect": "padmavathi,\nYochana IT solutions\npadmavathi@yochana.com\nReply to: padmavathi@yochana.com\nHello,I hope you are doing great.This is Padmavathi from Yochana IT Solutions, we have an urgent requirement with one of our clients, please go through the requirement below and let me know your interest. You can forward this opportunity to your friends or colleagues; so that we can help someone who may be desperately looking for opportunities. I sincerely appreciate your timeTitle : Cloud ArchitectLocation : Clayton, Missouri (Hybrid) Note: Only GC and USC visa AcceptableRole/ JD:HCL Cloud CoE (Practice) team is looking for an experienced customer-focused Azure Solution Architect with technical depth and architecture skills. In this role, you\u2019ll work closely with pre-sales, business units and engineering on some of HCL's largest and most strategic customer engagements to help identify, define, and architect solutions on Azure. Specifically, you will be part of a customer engaged team of technical PMs and engineers responsible for implementing new landing zone(s) and execute POCs and pilot migration projects. o Position - Solutions Architect (Azure)o Designation - Consultant/Senior Consultant/Solutions Architecto Experience - A minimum of 8-12 years of experience in a consulting or an architecture position with a software and/or services company. Roles & Responsibilities\u2022 Understand customer's IT estate, LOB applications, IT and business priorities and success measures to design implementation architectures and cloud native solutions \u2022 Collaborate with network, security, AD, backup, tools and application architects and SME's to develop enterprise grade solutions. \u2022 Develop deep relationships with key customer IT decision makers.\u2022 Define long term cloud strategy and mentor operations teams to implement the solutions \u2022 Keeping up to date with market trends and competitive insights and maintain technical skills and knowledge\u2022 Advocate new features and solutions to bring operational efficiency and cost reduction. \u2022 Act as a subject-matter expert on Microsoft Azure and assist Sales/Pre-Sales in RFP activities.Requirements \u2022 Subject matter level expertise on Azure Governance & Cost Management, Azure Network & Security, Azure Active Directory, Compute & Storage, Backup & DR, Monitoring \u2022 Extensive experience in conducting design workshops, documentation of HLD (High Level Design) documents. \u2022 Rich experience in Migration projects and hand-on experience with ASR/Azure Migrate\u2022 Good Knowledge of Azure DevOps, ARM Templates & PowerShell scripting\u2022 Experience in PaaS services and Containers is preferred. \u2022 Proven track record of building deep technical relationships with senior IT executives and growing data services in large or highly strategic accounts.\u2022 Demonstrated ability to adapt to new technologies and learn quickly.\u2022 Proven track record of driving decisions collaboratively.\u2022 Resolving conflicts and ensuring follow through with exceptional verbal and written communication skills.\u2022 Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management and developers) Thanks & Regards,Padmavathi Vindeepu,Resource Specialist, Farmington Hills, MI,Email Id: padmavathi@yochana.comhttps://www.linkedin.com/in/padmavathi-vindeepu-25b540261/\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "19_Urgent Requirement: Position:Cloud Architect(ONSITE) (Locals to DMV Area)": "ATI Team,\nAspire\nrecruiterpro@aspiretechus.com\nReply to: recruiterpro@aspiretechus.com\nPOSITION: Cloud Architect(ONSITE)Min8yrs Exp (Locals to DMV Area)DURATION:2-18 MonthsADDRESS:Washington DC 200038-10 years of experience. Subject Matter Expert in Azure and AWS cloud infrastructure and network technologieJOB DESCRIPTIONResponsibilities:Experience spanning at least two IT disciplines, including technical architecture, network management, application development, middleware, database management, security, or operations.Experience with multiple public cloud platforms, including AWS, Azure, and GCP.Experience relocating ERP application to a cloud-native environment.Ensures that standards set by Data, Security, Infrastructure, Platform, and other architecture domains are followed when designing and architecting cloud solutions.Demonstrate deep subject matter leadership of cloud architecture and implementation features (OS, multitenancy, virtualization, orchestration, elastic scalability).Manage the development and implementation of cloud strategy, develop the architecture governance framework, and define architecture foundations.Demonstrates expertise in conveying technical and functional concepts for a specific technical specialty.Identifies improvements to project standards to achieve high quality services/products.Identifies best practices and standards for the use of the product.Delivers support and design for industry specific technologies that require integration with systems or networks.Interacts with executive level business users or technical experts.Functions as a niche technical SME.Lead experience with technical expertise across large, complex implementations for systems.Define and enforce Cloud architecture best practices: availability, redundancy schemes, performance, Disaster Recovery, data, and integration patterns.Troubleshoot issues across the entire stack: IaaS, PaaS, services, applications, network, and security.1. Formulates and defines systems scope and objectives based on both user needs and a thorough understanding of business systems and industry requirements.Devises or modifies procedures to solve complex problems considering computer equipment capacity and limitations, operation time, and form of desired results. Includes analysis of business and user needs, documentation of requirements, and translation into proper system requirements specifications.Provides consultation on complex projects and is considered to be the top-level contributor/specialist of most phases of systems analysis, while considering the business implications of the application of technology to the current and future business environment.Minimum Education/Certification Requirements :Bachelor\u2019s degree in IT or related field or equivalent experience; or a current Azure and AWS Architect CertificationsRequired/Desired SkillsCloud DevOps experienceBroad technology experience across several of these areas including, applications development, relational or NoSQL database, DevOps, containers, CI/CDMust have minimum of 8 years of experience in the design and implementation of cloud workloads in Azure, AWS, or GCPExperience with cloud networking and network security, including virtual networks, network security groups, cloud-native firewalls, etc.Bachelor\u2019s degree in IT or related field or equivalent experience8 -10 yrs. experience in one or more architecture domains (e.g., business architecture, solutions architecture, application architecture)8 -10 yrs. preparing complex technical documentation8 - 10 yrs. experience in managing large operational cloud environments spanning multiple tenants through techniques such as Multi-Account managementMinimum 3 years of microservice architectural experienceMinimum of 3 years of experience working exclusively on designing and implementing cloud-native workloads.Experience with application lifecycle tools (Git, GitHub, Jenkins, Bamboo, Azure DevOps, Ansible, Terraform, Cloudformation, etc.).Certified AWS Solutions Architect ProfessionalCertified Microsoft Azure Solutions Architect ProfessionalThanks & RegardsATI TeamRecruiterpro@aspiretechus.com\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "20_Azure DevOps RDB expert": "Khushi Malhotra,\nTestingXperts\nkhushi.malhotra@testingxperts.com\nReply to: khushi.malhotra@testingxperts.com\nPosition: Azure DevOps RDB expertLocation: Remote\"Skill Score: Full Stack Sr. Software Development Engineer with 6-8 years of experience in modern .NET Web & API development with strong relational DB expertise. \u2022 High level of Expertise in C#, .NET, React, ASP.NET MVC, Javascript, JQuery, AJAX and CSS, HTML, LINQ, Vue.js, Visual Studio, SQL Server, TSQL, Entity Framework Core, SoapUI\u2022 Strong SQL experience with writing complex queries, table design, DB administration, stored procedures, functions, performance optimization, profiler utilization, etc\u2026\u2022 Azure development including Azure Functions, Azure Event Grid, Azure Storage, Resource Groups, Azure SQL, Azure Logic apps and Azure Service bus\u2022 Hands on experience in solving software design issues by applying design patterns such as Factory Pattern, Abstract Factory Pattern\u2022 Ability to contribute to design of complex architecture, UI and services with the use of modern technologies to meet the business requirements\u2022 Experience in design and implementation REST services and microservices\u2022 Clear communicator to be able to translate business requirements into technical solutions\u2022 Proficient with on TFS, Github, CICD, Azure DevOps, GitHub Actions, Jenkins, Powershell\u2022 Experience in developing automation code using Visual Studio and Selenium/Jmeter\u2022 Proficiency with unit test implementation using frameworks such as Microsoft Unit Test and NUnit\u2022 Experience working with Security Tools such as GitHub CodeQL & Dependabot, SonarQube, WhiteHat, etc...\u2022 Experience working within Scrum Agile development environment\u2022 Commitment to support aggressive bi-weekly release cycles - 26 releases per year Nice to Have:\u2022 Experience with application migration to public cloud (Azure)\u2022 Containerization (Kubernetes, Dockers), Infrastructure as Code (Terraform), application observability, messaging, stream architecture\u2022 Experience with non-relational DB patterns, implementation and large data reporting\u2022 Healthcare Industry Knowledge\"\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "21_Locals (AZ) Only -- Devops-GitHub Actions Engineer at Phoenix, AZ (Onsite)": "Manigandan,\nLorven Technologies Inc\nmanigandan.pa@lorventech.com\nReply to: manigandan.pa@lorventech.com\nHi ,Hope you are doing great!! Job Opening for GitHub Actions Engineer at Phoenix, AZ (Onsite) Job Title: GitHub Actions EngineerLocation: Phoenix, AZ (Onsite)Duration: 1+ Year (Contract) Description:GitHub Actions EngineerLooking for an engineer to be part of GitHub Actions support. Someone with good CI/CD & GitHub Actions knowledge is a must. Need to be good at any one Programming language Thanks & Regards ManigandanRecruiterLorven Technologies, Inc.101 Morgan Lane | Suite 209 | Plainsboro | NJ 08536\u260e 609 374 9629 | \ud83d\udcf1 470-440-2646 \u2709 manigandan.pa@lorventech.com | \ud83c\udf10www.lorventech.comhttps://www.linkedin.com/in/manigandan-p-a-22b88693/ Inc 5000 Fastest Growing Companies in America\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "22_Sr Cloud Network Engineer : Bellevue, WA (Onsite)": "Amol,\nChabeztech\namol@chabeztech.com\nReply to: amol@chabeztech.com\nTitle: Sr Cloud Network Engineer Job Location:- Bellevue, WAManadatory requirement: Telecom industry experience Below is the Job Description Reqs Key Responsibilities\u2022 Oversee the network onboarding process for new users and systems in the Cloud environment\u2022 Provision and configure network resources in the Cloud, ensuring compliance with security policies and government regulations.\u2022 Implement secure network architectures, including Virtual Private Clouds (VPCs), subnets, routing tables, and network access control lists across AWS, Azure, and other cloud platforms.\u2022 Configure and manage cloud networking services for secure connectivity between on-premises and cloud environments, such as AWS Direct Connect, Azure VPN Gateway, and transit gateways.\u2022 Implement network security controls, such as security groups, network firewalls, and web application firewalls to protect against unauthorized access and cyber threats.\u2022 Monitor network traffic and security logs using cloud services for flow logs, activity trails, and threat detection to identify and respond to potential security incidents.\u2022 Collaborate with cross-functional teams to ensure secure integration of applications and services into the cloud network infrastructure.\u2022 Conduct regular network assessments and audits to ensure compliance with internal and external requirements.\u2022 Develop and maintain comprehensive network security policies, procedures, and documentation in compliance with security standards.\u2022 Provide technical support and troubleshooting for Cloud network-related issues\u2022 Stay up-to-date with the latest cloud networking services, security features, and best practices across multiple platforms\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "23_Urgent Need: Azure Architect with EventHub, Snowflake and Cosmos DB, 100% Remote": "SAPNA,\nITECS\nsapna@itecsus.com\nReply to: sapna@itecsus.com\nUrgent need from Infocepts. Only US Citizens. Phone + Video interview.100% Remote from US location. Primary Skills: Technologies/Tools: Azure, EventHub, Snowflake, Cosmos DB, Managed Airflow, API Gateway & DBT Job Title: Azure Architect with EventHub, Snowflake and Cosmos DBWork Location: Onshore in USA \u2013 100% Remote Purpose of the Position: Purpose of this role is to design and build data architecture for a migration project. Major responsibilities under this role would be to create high level and low level design for data integration framework, translate the business requirements into technical prototypes, help developers in developing the data integration pipelines, perform peer reviews of the code, own the technical delivery of the DI part from inception to the deployment. Also own the technical consultation for existing or new clients during initial phase of any initiative and help in proposals and pre-sales initiatives. Must Have Technical Experience:At least 12 years of IT experience; Minimum 5 years of experience on AzureMust have minimum 5+ years of experience in implementing and managing Azure Cloud components.Expertise in Python and SQL best practicesExperience in data and analytics domainKnowledge of integrating Azure Active Directory with other servicesIn-depth experience of key Azure services for data integration, BI and processing services including but not limited to Azure HDInsight, Azure Databricks, Azure Portal, Log Analytics, Azure Data Factory, , Azure Search, Azure Functions, Azure Stream Analytics, Managed Airflow and Azure Event Hub.Experience in Azure cosmos DB over PostgreSQL, mongo dB and live streaming with Azure EventHub.Experience on Azure functions with Python language.Experience in migration of on-prem applications and data analytics workload to Azure cloud. Experience in designing Azure cloud architecture and operationalizing solutions around monitoring, alerting, logging etc.Working knowledge on Architecture design, Modelling, prototyping, and benchmarking of DataStore/ EDW solutions.Knowledge of variety of advanced architecture, tools, and concepts across all layers of modern distributed technology stack covering the big data ecosystem.Knowledge of Azure storage services such as Azure storage account, Azure Cosmos DB, Azure Time Series Insights, Redis Cache, SQL Databases, Table StorageExperience with programming languages such as PythonExperience in enabling DevOps automation for Azure with appropriate security and privacy considerations.Knowledge of configuring and provisioning networks and infrastructure in cloudGood to have knowledge of Big Data ecosystems such as Hadoop / Hive, HDFS, Spark, YARN and others.Good to have Snowflake, Scala, and Java experienceGood to have Technical Experience:Pre-sales experience will be an added advantage.Any BI experienceExperience in any other cloud technologies like AWS, ALI, GCP.Snowflake, DBT, Scala and JavaTechnologies/Tools: Azure, EventHub, Snowflake, Cosmos DB, Managed Airflow, API Gateway & DBTQualifications:Bachelor\u2019s degree in computer science, engineering, or related field (master\u2019s degree is a plus)Demonstrated continued learning through one or more technical certifications or related methods. ---------------------------------------------------------------------------------------------------------------------------Please follow the submission format table provided and ensure all required information is included with each submission with resume. Incomplete submissions will be disqualified. Candidate Legal Name (As per Documents) Summary Year of experience in each skillset: Email Address Phone Number Work Authorization Current Location For non-local, Relocation (Yes/No) Pay Rate Current working status Reason for change LinkedIn Profile Availability for Interview (Please provide 03 time slots) Availability for Joining the project\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "24_DevOps Engineer": "Pallavi,\nnss\nrec1@nityainc.com\nReply to: rec1@nityainc.com\nDiscover an exciting remote DevOps engineering role dealing with management solutions for law firms and academic institutions. Focused on mitigating risk and driving business insights, this contract involves work in AWS or Azure. You'll use Terraform or cloud formation and containerization tools such as Kubernetes or Helm.This company has become profitable and is scaling consistently, fueling upward moment within and surrounding the position. Investments into the company are also contributing to migrating their systems from on-perm to the cloud. The job provides a great quality of life, full benefits such as 401k matching, as well as other exciting perks!Contract Duration: 6 - 12 MonthsRequired Skills & ExperienceAzureTerraformAzure DevOpsAKSDesired Skills & ExperienceAzureTerraformAzure DevOps with a greater concentration of experience with GitlabAKS to be able to maintain, nothing too involvedLots of experience with analyticsComfortability in a complicated APIWhat You Will Be DoingTech Breakdown40% AWS or Azure30% Terraform or Cloud Formation30% Kubernetes or HelmDaily Responsibilities50% Managing API Systems30% Team Collaboration30% Transitional workEmployers have access to artificial intelligence language tools (\u201cAI\u201d) that help generate and enhance job descriptions and AI may have been used to create this description. The position description has been reviewed for accuracy and Dice believes it to correctly reflect the job opportunity.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "25_DevOps Engineer": "Pallavi,\nnss\nrec1@nityainc.com\nReply to: rec1@nityainc.com\nDiscover an exciting DevSecOps Engineering role in Moorestown, NJ. The full-time position is for a distinguished technology company specializing in building CI/CD pipelines and working within their on-perm infrastructure. Technical requirements include using Ansible to drive automation, as well as developing overall software security.This onsite position allows for a transition to a hybrid or flex schedule after getting accustomed to their systems, allowing for a more dynamic and adjustable workday. The role will greatly develop the ability to maintain server infrastructure and security practices. After asserting yourself in the position the conversion from hourly to salary also is accompanied with a sign on bonus.Required Skills & ExperienceAnsibleJenkinsLinuxOn-premise InfrastructureExperience building CI/CD pipelinesAnsible to drive automation, and focus on the security of their systemsAPI security, network security, overall software securityDesired Skills & ExperienceAnsibleJenkins (with Gitlab)LinuxOn-premise InfrastructureExperience building CI/CD pipelinesBe experienced with infrastructure as code, and set up disaster recovery.Contract Duration: 6 MonthsWhat You Will Be DoingTech Breakdown60% Building CI/CD Pipelines40% Developing Security of SystemsDaily Responsibilities60% Hands On10% Management Duties30% Team CollaborationThe OfferSign on bonus post flip after first 6 monthsApplicants must be currently authorized to work in the US on a full-time basis now and in the future.Employers have access to artificial intelligence language tools (\u201cAI\u201d) that help generate and enhance job descriptions and AI may have been used to create this description. The position description has been reviewed for accuracy and Dice believes it to correctly reflect the job opportunity.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "26_Salesforce Developer with Financial Services Cloud Experiences - Onsite - Plano, TX - Locals Only - H1B Only": "PAVITHRA,\nXFORIA\npavithra.s@xforia.com\nReply to: pavithra.s@xforia.com\nSetup, customize and develop Salesforce.com and related app implementations, drawing on your relevant past experience and understanding of best practices surrounding Salesforce platformDevelop and enhance custom applications & features on the platform, by leveraging Salesforce Service Cloud, Sales Cloud and APIsBuild Salesforce integration with other applications, using relevant APIs and Integration frameworksSupport product owner/s with refinement of user requirement and lead the functional/technical solution architecture & designEnsure the platform is run as intelligently and efficiently as possible through continuous improvement, periodic code reviews, analysis of platform/governor limitsWork in an agile environment with a team of developers, product owners and test engineersAct as a coach/guide to junior engineers, and foster a culture promoting technical growth, respect between team-members, empowerment, continuous innovation and funSupport in maintaining the overall quality and integrity of the platform through appropriate quality assurance activities and automation testingLogging and managing incidents and defects through to resolutionSupport in deployment and release activitiesMinimum of 8 +years experience working on the Salesforce Financial Service Cloud implementations in a multi org structure .Strong Salesforce development experience with hands on knowledge of LWC, Aura Components, Apex and VisualforceStrong understanding of declarative automation features within the platformHands on experience with Version/Source Control and Continuous Integration tools, and DevOps principles Strong experience and understanding of Salesforce APIs, integration patterns, and hands-on knowledge on writing custom web servicesStrong understanding of Salesforce coding best practices, design patterns and enterprise patternsStrong knowledge and experience around Salesforce service cloud and Sales Cloud features\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "27_AWS Engineers - W2": "Deepak Singh,\nVyze Inc\ndeepak@vyzeinc.com\nReply to: deepak@vyzeinc.com\nJob Description -AWS Engineers - W2 onlyRemoteUSC/GC onlyLooking for someone with Terraform, Python, and AWS. This will be new development and support. Job Description:As an Engineer 2, candidate will be responsible for using candidate's technical knowledge of professional concepts to solve business problems.Client is looking for a talented individual who can serve as a subject matter expert in their area of focus and represent their department on complex assignments.Candidate will be responsible for evaluating elements of technology's effectiveness through requirements gathering, testing, research, and investigation, and making recommendations for improvements resulting in increased quality and effectiveness.Candidate will be required to listen to and evaluate customer needs to determine and provide high-quality solutions that align with customer expectations.Client Mobility is seeking an Engineer 2 to support client\u2019s rapidly growing cloud enablement engine application and infrastructure portfolio.This role will automate configurations and templates for customer use to consume various AWS-based services, manage AWS-based services, measure and maintain reliability through instrumentation and monitoring, and interface with multiple development teams to provide services and support.Candidate will create and modify medium to complex Python and Terraform (HCL) code to enable our customers to more easily consume AWS services.Candidate will perform local development builds, being a primary contributor in code reviews, planning, testing, and coordinating of implementation activities.Participate in on-call rotation, which includes 24/7 support every two months of multiple production environments.Candidate will work with cloud vendors and external technical support on upgrades, problem resolution, and design issues.This is an exciting role in a fast-paced, collaborative team that strives to build and foster close working relationships with its application development customers.Required:2 plus years of software development experience.2 plus years of Python (boto3) and Terraform development experience.2 plus years of experience with core Amazon Web Services such as Route 53, EC2 (AMI, EBS, ELB, ASG), S3, CloudWatch, CloudFormation,ElasticBeanstalk, ElastiCache, IAM, VPC, RDS, DynamoDB, SQS, and SNS.Must be committed to incorporating security into all decisions and daily job responsibilities.Must be able to coach and mentor team members and customers.Experience with the design and build of web application cloud infrastructure.Experience in and demonstrable knowledge of Linux command line interface.Experiences with software design methodologies, information systems architecture, object-oriented design, and software design patterns.Excellent verbal and written communication skills.Excellent customer service skills.Familiarity with Agile/Scrum methodology.Ability to quickly triage problems, determine root cause and drive resolution.Familiarity with Software Development Lifecycle (SDLC)Knowledge of version control tools, such as git, BitBucket, and GitHubBachelor's degree in Computer Science, Computer Information Systems, Management Information Systems, or related field.Preferred:Experience in Jira, Confluence, Maven, and Jenkins.Experience with Linux package management (rpm, yum, dnf, etc).Experience with HTTP/Proxy servers (Apache, Nginx).Experience installing, configuring, and troubleshooting application platforms, with a preference for experience in working with Java web applicationplatforms (e.g., Tomcat, Spring Boot, etc.).Experience with monitoring and alerting tools such as Dynatrace, Cloudwatch or similar.Experience with log aggregation and management tools such as Splunk.Experience working with configuration management tools. Examples: Ansible.Systems performance tuning and load testing is a plus.Familiarity with large-scale systems and methodologies. Regards!! Deepak SinghLead Technical Recruiter | IT Healthcare & InformaticsEmail: deepak@vyzeinc.com\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "28_Urgent hiring on ::Job Description -DevOps Engineer :: Location: Remote :: Duration: 12 months": "Rasmita Bhuyan,\nAdventa Tech INC\nrasmita@adventatech.com\nReply to: rasmita@adventatech.com\nJob Description -DevOps EngineerLocation: RemoteDuration: 12 monthsVisa : CITIZEN,GREEN CARD,H4 EAD,H1B,GC EADMOi : SkypeJob Description:Excellent working experience in CI/CD to Setup CI/CD pipeline to achieve fully automated CI/CD process.Troubleshoot and rectify build pipeline issues.Schedule automated build and deployment and execute ad-hoc build request by AD teamHands-on knowledge of Bit-bucket, GIT commands and branching strategies.Other Skills:Knowledge of Unix commands required for day to day operations and troubleshooting.Scripting knowledge for automation.Knowledge of webapps (weblogic, Tomcat, Apache , IBM HTTP etc) and their troubleshooting.Working knowledge of schedulers ( control M, Autosys etc).SSL/TLS certificate management.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "29_Hiring for Azure  solution architect Engineer || Chicago, IL": "rajan,\nquantumworldit\nrajan@quantumworldit.com\nReply to: rajan@quantumworldit.com\nDear Partner, Trust you are doing well ! My name is Rajan Pandey and I am a Staffing Specialist at Quantum World Technologies Inc. I am reaching out to you on an exciting job opportunity with one of our clients. Job Title \u2013 Terraform EngineerLocation \u2013 Chicago, ILDuration- 6 Months +Hire Job Description We are seeking a highly skilled DevSecOps Engineer to integrate security practices into our DevOps processes. The ideal candidate will be responsible for implementing, managing, and improving our security posture in our software development lifecycle.Key Responsibilities:Incorporate security measures into CI/CD pipelines.Develop and Maintain automation scripts and tools for security processes.Set up and manage security monitoring tools and generate reports on security incidents and vulnerabilities.Work closely with development, operations and security teams to ensure security is intergated into the development lifecycleEnsure that systems and processes comply with security standards and regulationsLead incident response activities, including investigation and mitigation of security breachesConduct regular security assessments, vulnerability scans and penetration testsMaintain up-to-date documentation of security procedures, policies and protocolsProvide training and guidance to teams on security best practices and emerging threatsQualificationsProven experience as a DevSecOps engineer or in a similar roleStrong Knowledge of DevOps pracitces and tools like Jenkins, Git, Docker and KubernetesProficiency in scripting language like Python and BashExperience with security tools like snyk, Fortify and NessusFamiliarity with cloud platforms especially Azure and their security featuresIn-depth understanding of security protocols and security frameworksExcellent problem solving skills and attention to detailStrong communication and collaboration skillsExperience with IaC tools espacially very good and strong in TerraformShould you be interested, please send me a copy of your resume in word format along with the following details ASAP.Full Name:Current Location:Hourly rate on C2C/W2:Work Authorization:Earliest Available date to start:Date and times available to interview:Two Professional References:(Preferably Supervisory references): Regards, RajanMail ID : rajan@quantumworldit.comCell : +1 805-667-0372Linkedin: www.linkedin.com/in/rajanpandeyQuantum World Technologies Inc.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "30_Looking for DEVOPS ENGINEER, Remote": "Mudassir,\nAvance consulting\nmudassir.uddin@avanceservices.com\nReply to: mudassir.uddin@avanceservices.com\nJob Title: DEVOPS ENGINEERLocation: RemoteMode : Contract (6+ Months) ROLES & RESPONSIBILITIES\u2022 Understanding customer requirements and project KPIs\u2022 Implementing various development, testing, automation tools, and IT infrastructure\u2022 Planning the team structure, activities, and involvement in project management activities.\u2022 Managing stakeholders and external interfaces\u2022 Setting up tools and required infrastructure\u2022 Defining and setting development, test, release, update, and support processes for DevOps operation\u2022 Have the technical skill to review, verify, and validate the software code developed in the project.\u2022 Troubleshooting techniques and fixing the code bugs\u2022 Monitoring the processes during the entire lifecycle for its adherence and updating or creating new processes for improvement and minimizing the wastage\u2022 Encouraging and building automated processes wherever possible\u2022 Identifying and deploying cybersecurity measures by continuously performing vulnerability assessment and risk management\u2022 Incidence management and root cause analysis\u2022 Coordination and communication within the team and with customers\u2022 Selecting and deploying appropriate CI/CD tools\u2022 Strive for continuous improvement and build continuous integration, continuous development, and constant deployment pipeline (CI/CD Pipeline)\u2022 Mentoring and guiding the team members\u2022 Monitoring and measuring customer experience and KPIs\u2022 Managing periodic reporting on the progress to the management and the customer TOOLS & TECHNOLOGIES \u2022 Jenkins\u2022 GitHub Actions\u2022 Continuous integration / Continuous deployment (CI/CD Pipelines)\u2022 Artifactory\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "31_Looking for DEVOPS ENGINEER, Remote": "Mudassir,\nAvance consulting\nmudassir.uddin@avanceservices.us\nReply to: mudassir.uddin@avanceservices.us\nJob Title: DEVOPS ENGINEERLocation: RemoteMode : Contract (6+ Months) ROLES & RESPONSIBILITIES\u2022 Understanding customer requirements and project KPIs\u2022 Implementing various development, testing, automation tools, and IT infrastructure\u2022 Planning the team structure, activities, and involvement in project management activities.\u2022 Managing stakeholders and external interfaces\u2022 Setting up tools and required infrastructure\u2022 Defining and setting development, test, release, update, and support processes for DevOps operation\u2022 Have the technical skill to review, verify, and validate the software code developed in the project.\u2022 Troubleshooting techniques and fixing the code bugs\u2022 Monitoring the processes during the entire lifecycle for its adherence and updating or creating new processes for improvement and minimizing the wastage\u2022 Encouraging and building automated processes wherever possible\u2022 Identifying and deploying cybersecurity measures by continuously performing vulnerability assessment and risk management\u2022 Incidence management and root cause analysis\u2022 Coordination and communication within the team and with customers\u2022 Selecting and deploying appropriate CI/CD tools\u2022 Strive for continuous improvement and build continuous integration, continuous development, and constant deployment pipeline (CI/CD Pipeline)\u2022 Mentoring and guiding the team members\u2022 Monitoring and measuring customer experience and KPIs\u2022 Managing periodic reporting on the progress to the management and the customer TOOLS & TECHNOLOGIES \u2022 Jenkins\u2022 GitHub Actions\u2022 Continuous integration / Continuous deployment (CI/CD Pipelines)\u2022 Artifactory\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "32_AWS EKS Engineer": "Ben Clark,\nTech Talent Connect LLC\nben@techtalentconnect.com\nReply to: ben@techtalentconnect.com\nClient: AMEXJob Title: AWS EKS EngineerLocation: Phoenix, AZ (Onsite) (Locals preferred)Duration: 6+ Months ContractRate: $60/hr on C2CRequired Skills:\u00b7 Experience with CI/ CD, Git (GitHub, GitLab, BitBucket, SVN), Kubernetes, Linux, AWS\u00b7 Bachelor's degree in information technology, Computer Science or the equivalent combination of training, education, and experience\u00b7 8 years of experience in managing Kubernetes clusters, with a focus on AWS EKS.\u00b7 Experience with CI/CD tools (Jenkins, GitLab CI, CircleCI).\u00b7 Strong experience with AWS services.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "33_NEED - Cloud Architect MORE THAN 10+ YEARS OF CANDIDATES LOOKING FOR USC ONLY - Overland Park, Kansas (onsite)": "Ayushi,\nCygnuspro\nayushi@cygnuspro.com\nReply to: ayushi@cygnuspro.com\nHi,This is Ayushi Kaushik from Cygnus Professionals. I have an urgent job requirement matching your profile. If You are Interested, Please reply with updated resume at ayushi@cygnuspro.com or directly reach me Role: Cloud ArchitectLocation: Overland Park, Kansas (onsite)Duration: Long Term Contract JD :Roles & ResponsibilitiesUnderstand customer's IT estate, LOB applications, IT and business priorities and success measures to design implementation architectures and cloud native solutionsCollaborate with network, security, AD, backup, tools and application architects and SME's to develop enterprise grade solutions. Develop deep relationships with key customer IT decision makers.Define long term cloud strategy and mentor operations teams to implement the solutionsKeeping up to date with market trends and competitive insights and maintain technical skills and knowledgeAdvocate new features and solutions to bring operational efficiency and cost reduction.Act as a subject-matter expert on Microsoft Azure and assist Sales/Pre-Sales in RFP activities.RequirementsSubject matter level expertise on Azure Governance & Cost Management, Azure Network & Security, Azure Active Directory, Compute & Storage, Backup & DR, MonitoringExtensive experience in conducting design workshops, documentation of HLD (High Level Design) documents.Rich experience in Migration projects and hand-on experience with ASR/Azure MigrateGood Knowledge of Azure DevOps, ARM Templates & PowerShell scriptingExperience in PaaS services and Containers is preferred.Proven track record of building deep technical relationships with senior IT executives and growing data services in large or highly strategic accounts.Demonstrated ability to adapt to new technologies and learn quickly.Proven track record of driving decisions collaboratively.Resolving conflicts and ensuring follow through with exceptional verbal and written communication skills.Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management and developers)Thanks & RegardsAyushi KaushikCygnus Professionals3490 US Highway 1Princeton, NJ 08540 E: ayushi@cygnuspro.comLinkedIn: https://www.linkedin.com/in/ayushi-kaushik-032706217\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "34_Sr. DevOps Architect": "Zara,\nTechRakers\nzararaza@techrakers.com\nReply to: zararaza@techrakers.com\nJob Title: Sr. Devops ArchitectLocation : Chicago, IL \u2013 Onsite Duration: Long Term List of Mandatory Tools/ Technology: GitHub Platform \u2013 Git Action mandatoryBit Bucket \u2013 Migration to GitHub mandatoryAzure mandatorySonarQubeApp DynamicsKubernetes SUMMARYThis position is responsible for provisioning, managing, monitoring, and decommission services in an in-house or on-premises hosted environment. This role provides support and techniques for automating provision and management of infrastructure in a distributed environment through scripting or infrastructure as code. All tasks are planned with time estimates and performed in a timely manner. The DevOps Engineer will partner with the development team to facilitate better coordination among operations, development, and testing functions by automating and streamlining the integration and deployment processes. WORK PERFORMEDPerforms system administration (Linux/Unix or Windows) at the command-line level.Maintains Docker and Kubernetes infrastructure.Build pipes to migrate on prem work loads to cloudProvides guidance and expertise on system options including identifying risk, impact and costs vs. benefits. Create requirements and development forecasts to allow for timely and accurate planning of projects.Installs and configures solutions, implements reusable components, translates technical requirements, assists with all stages of test data, develop interface stubs and simulators and performs script maintenance and updates.Deploys new modules and upgrades and complete fixes including CI/CD, continuous testing, app performance monitoring, infrastructure settings and configurations.Performs routine application maintenance tasksCreates requirements and procedures for implementing routine maintenance.Troubleshoots existing information systems for errors and resolving those errorsProvisions multi-tier architectures: load balancers, caching, web servers, application servers, databases, and networking. Basic monitoring techniques in a dynamic environment.Infrastructure as Code: design with security, configuration management, integration, deployment, performance monitoring and tuning, automation of infrastructure.Creates automated build and release pipelines for code deploymentsPerforms other duties, as assigned. DOMAIN, KNOWLEDGE, SKILLS AND ABILITIESBanking domain experienceKnowledge of Windows and Linux is requiredExcellent research and self learning skills is requiredKnowledge of a scripting language (PowerShell, Bash etc.) is requiredExcellent time management skills are requiredKnowledge of Azure and Azure portal is requiredKnowledge of Azure Kubernetes, Azure API Management, Azure Application Gateway is an assetStrong documentation skills are requiredKnowledge of Automation Tools (ex. Azure Dev Ops, GitHub (Git Action) is requiredCapability to work independently is required\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "35_AWS Devops Engineer Remote Role": "Shubham Singh,\nStellentit\nshubham@stellentit.com\nReply to: shubham@stellentit.com\nDevOps/Cloud EngineerLocation: RemoteInterview: Phone + SkypeMax Rate: $40-$43/hr on c2c USC/GC Only Job Description:Need a strong DevOps/Cloud Engineer with below hands on skills5+ years\u2019 experienceAWS (ECS/EKS, Lambda, CloudTrail etc)NGINX- Must HaveSplunk Monitoring, queriesNew Relic TerraformJenkinsIBM WebSphere Shubham Singh- Sr. Technical RecruiterEmail- shubham@stellentit.com STELLENT IT \u2013 A Nationally Recognized Minority Certified Enterprise\"Happiness can be found, even in the darkest of times, if one only remembers to turn on the light.\" - JK Rowling\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "36_Azure Terraform Developer": "john,\nVaaridatech\nchand@vaaridatech.com\nReply to: chand@vaaridatech.com\nJob Summary: We are seeking an experienced Azure Terraform Developer to join our team. As an Azure Terraform Developer, you will be responsible for designing, implementing, and maintaining infrastructure as code using Terraform on the Azure cloud platform. You will work closely with our development teams to ensure seamless integration of infrastructure and applications. Responsibilities: - Design and implement scalable and secure infrastructure on Azure using Terraform- Develop and maintain Terraform configurations, modules, and scripts- Collaborate with development teams to integrate infrastructure with applications- Implement infrastructure as code (IaC) best practices and standards- Manage and optimize Azure resources using Terraform- Troubleshoot and resolve infrastructure-related issues- Stay up-to-date with the latest Azure and Terraform features and releases Requirements: - 2+ years of experience in Azure cloud computing and Terraform- Strong understanding of Azure services (e.g., Virtual Machines, Storage, Networking)- Experience with Terraform configuration language (HCL)- Familiarity with Azure DevOps and CI/CD pipelines- Strong programming skills in languages like Python, PowerShell, or Bash- Excellent problem-solving and analytical skills- Bachelor's degree in Computer Science or related fieldNice to Have: - Experience with other cloud platforms (AWS, GCP)- Knowledge of Azure security and compliance best practices- Certification in Azure or Terraform (e.g., Azure Solutions Architect, Terraform Certified Associate)\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "37_Need Terraform Engineer || Phoenix, AZ || Onsite": "Prashanth B,\nTekgence\nprashanth.b@tekgence.com\nReply to: prashanth.b@tekgence.com\nTitle: Terraform EngineerLocation: Phoenix, AZDuration: Long term Requried: Need Terraform Engineer with AWS / AZURECoding test is mandatory --Regards,Prashanth B | Tekgence Inc.Talent Acquisition Specialist Email: prashanth.b@tekgence.com | Website: www.tekgence.com6655 Deseo Dr \u2022 Suite 104 \u2022 Irving, TX \u2022 75039\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "38_12+ Years Cloud Architect with AWS &amp; Azure - Washington DC (onsite)": "Susan,\nCapitaltechsolutions\nsusan@capitaltechsolutions.com\nReply to: susan@capitaltechsolutions.com\nHello,We are looking for the candidates for the below position. Please find the below Job Description and update me with the required details.Role : Cloud ArchitectClient: DC Government (Onsite)Location : Washingto, D.C. (Onsite)Responsibilities: Experience spanning at least two IT disciplines, including technical architecture, network management, application development, middleware, database management, security, or operations.Experience with multiple public cloud platforms, including AWS, Azure, and GCP.Experience relocating ERP application to a cloud-native environment.Ensures that standards set by Data, Security, Infrastructure, Platform, and other architecture domains are followed when designing and architecting cloud solutions.Demonstrate deep subject matter leadership of cloud architecture and implementation features (OS, multitenancy, virtualization, orchestration, elastic scalability).Manage the development and implementation of cloud strategy, develop the architecture governance framework, and define architecture foundations.Demonstrates expertise in conveying technical and functional concepts for a specific technical specialty.Identifies improvements to project standards to achieve high quality services/products.Identifies best practices and standards for the use of the product.Delivers support and design for industry specific technologies that require integration with systems or networks.Interacts with executive level business users or technical experts.Functions as a niche technical SME.Lead experience with technical expertise across large, complex implementations for systems.Define and enforce Cloud architecture best practices: availability, redundancy schemes, performance, Disaster Recovery, data, and integration patterns.Troubleshoot issues across the entire stack: IaaS, PaaS, services, applications, network, and security.1. Formulates and defines systems scope and objectives based on both user needs and a thorough understanding of business systems and industry requirements.Devises or modifies procedures to solve complex problems considering computer equipment capacity and limitations, operation time, and form of desired results. Includes analysis of business and user needs, documentation of requirements, and translation into proper system requirements specifications.Provides consultation on complex projects and is considered to be the top-level contributor/specialist of most phases of systems analysis, while considering the business implications of the application of technology to the current and future business environment. Minimum Education/Certification Requirements :Bachelor\u2019s degree in IT or related field or equivalent experience; or a current Azure and AWS Architect Certifications Thanks,Susan,susan@capitaltechsolutions.com\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "39_Immediate Interview  || AWS LEAD (TECHNICAL LEAD) || San Antonio, TX": "Prashant,\nIntellectt INC\nprashant@intellectt.com\nReply to: prashant@intellectt.com\nHi,Job Title: AWS LEAD (TECHNICAL LEAD)Position Type: CTHLocation: Onsite San Antonio, TX Experience needed: 12\u201320 years We can schedule an immediate interview. Overview:Looking for talented cloud Developer (Lead) responsible for developing design and architecture to support cross domain business capabilities for P&C division. Candidate will work closely with technologists from P&C domains and help migrate them to private and public cloud. Candidate will focus on the intentional architecture and provide mentorship on emergent architecture to the technical teams. Candidate will have hands-on experience in cloud architectures (SaaS, PaaS, IaaS) and deep interest and experience in broad enterprise platforms and cloud patterns. Job Description:Participate in producing conceptual, solution and component-level architectures and associated artifacts.Develop cross domain business requirements reference architecture for transition and target state and contribute to the cloud related patterns and implementations.Develop common components for shared business capabilities with Standards and best practices. Develop the transition architecture using services offered by AWS and private cloud.Migrate legacy applications to AWS and private cloud. Hands on experience with AWS cloud networking including VPCs, Subnets, Security Groups, ACLs, Transit Gateways, ALB/NLB, Route53, ACM, API Gateway and related technologies.Understanding of networking processing, protocols, and standards - TCP/IP, UDP, DNS, HTTPHands on experience with security mechanisms including mTLS, x509, OpenID Connect, JWT/JWE, OAuth2, PEP/PDP, SAML, WS-Security, Basic Auth and ABAC/RBAC based policies.Hands on \u201ccode first\u201d development of cloud configuration and components from the ground up using tools like Gitlab and TerraformStrong hands-on experience in one or more development languages including Java, python, Golang.Experience with Open Trace, AWS Cloud Watch, DataDog, Prometheus, ELK, Grafana, Hystrix,, App Dynamics, NetCool and other tools to ensure the cloud is operating as expected.Hands on experience with continuous delivery (CD) tooling including Jenkins, GitLab, Travis CI, GoCD and others.Hands on experience with Containers including tools like Docker, Kubernetes, ECS/ECR, and other related technologies and tools.Experience in explaining complex technology decisions and developing high trust relationships with stakeholders.Ability to develop target state architecture using services offered by AWS and private cloud and vision to develop the transition architecture.Ability to design patterns for moving legacy applications to AWS and private cloud.Hand on experience with common architecture patterns (microservices, event-driven, REST, NO SQL databases, Caches, etc.) and services offered by AWS (S3, EKS, Lambda, RDS, elastic search, etc.)Hands on experience addressing operational and non-functional concerns (e.g. scalability, performance, maintainability, load distribution, resilience and recovery, etc.)Experience with SAFe framework or other similar agile frameworks.Experience with Java, Kafka, Spring, Redis, Kubernetes, OpenShift and others.Guidewire experience is big plus.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "40_DevOps Engineer - Contract Role": "Raghu Prasad,\nBlue Ocean Ventures\nraghu.prasad@blue-oceanventures.com\nReply to: raghu.prasad@blue-oceanventures.com\nHi Hope everyone doing well. Role: DevOps EngineerLocation: Alpharetta,GA/Berkeley Heights,NJ/Omaha,Nebraska (5 days a week onsite(100% Onsite)Local profiles with DL As a Kubernetes Container Platform Engineer you will play a pivotal role in designing, implementing, and operating container services platforms across on-premises and cloud environments. Your focus will be on seamless integration with other tools through robust Continuous Integration (CI) and Continuous Delivery (CD) pipelines. Here are the key responsibilities:Key Responsibilities:Platform Design and Implementation:Architect, implement, and operate container services platforms, emphasizing integration with CI/CD pipelines.Leverage automation to enhance efficiency and minimize manual tasks.Meticulously assess risks while ensuring task efficiency.Technical Issue Resolution:Analyze, diagnose, replicate, and resolve technical issues reported by customers using Fiserv PaaS and CaaS platforms.Develop maintainable, reusable software from a consumer-centric perspective.Take ownership of unresolved issues, seeking in-depth knowledge for timely resolution.Support and Documentation:Handle and maintain support requests from business unit customers.Collaborate with other engineering groups to triage customer and business unit issues.Contribute to building and peer-reviewing knowledge base articles and product documentation.Qualifications:Experience and Expertise:Minimum of 5 years of hands-on experience building and maintaining Container Platforms (e.g., PAS/TAS, PKS/TKGI, GKE, IBM Redhat OpenShift, ARO, ROSA).Proficiency in deploying and supporting Kubernetes on at least one public IAAS provider (Azure, Amazon, GCP, Alibaba).Strong networking fundamentals, including TCP/IP, subnetting, socket vs. connect timeouts, routing, and DNS.Experience designing and implementing Infrastructure as Code APIs using tools like Swagger.Solid understanding of virtual computing environments, including Hypervisors and load balancing concepts.Familiarity with Identity Management, Access Management, and Certificate Management.Demonstrated competency in programming/scripting languages (with a preference for Go, Ansible, Terraform, and Python).Hands-on experience with distributed systems (Windows and Linux) and virtualization software (VMware).DevOps Practices:Understanding of DevOps practices, with hands-on experience in Automation/Continuous Integration using tools like Jenkins, Harness, RunDeck, GitLab, and GitHub.Additional Skills (Preferred):Experience with NSX, NSX-T, and Panorama.Familiarity with Vsphere7 and TKG.Background in DevOps methodologies.Excellent communication skills.On-call experience.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "41_Sr. DevOps Architect": "Zara,\nTechRakers\nzararaza@techrakers.com\nReply to: zararaza@techrakers.com\nJob Title: Sr. Devops ArchitectLocation : Chicago, IL \u2013 Onsite Duration: Long Term List of Mandatory Tools/ Technology: GitHub Platform \u2013 Git Action mandatoryBit Bucket \u2013 Migration to GitHub mandatoryAzure mandatorySonarQubeApp DynamicsKubernetes SUMMARYThis position is responsible for provisioning, managing, monitoring, and decommission services in an in-house or on-premises hosted environment. This role provides support and techniques for automating provision and management of infrastructure in a distributed environment through scripting or infrastructure as code. All tasks are planned with time estimates and performed in a timely manner. The DevOps Engineer will partner with the development team to facilitate better coordination among operations, development, and testing functions by automating and streamlining the integration and deployment processes. WORK PERFORMEDPerforms system administration (Linux/Unix or Windows) at the command-line level.Maintains Docker and Kubernetes infrastructure.Build pipes to migrate on prem work loads to cloudProvides guidance and expertise on system options including identifying risk, impact and costs vs. benefits. Create requirements and development forecasts to allow for timely and accurate planning of projects.Installs and configures solutions, implements reusable components, translates technical requirements, assists with all stages of test data, develop interface stubs and simulators and performs script maintenance and updates.Deploys new modules and upgrades and complete fixes including CI/CD, continuous testing, app performance monitoring, infrastructure settings and configurations.Performs routine application maintenance tasksCreates requirements and procedures for implementing routine maintenance.Troubleshoots existing information systems for errors and resolving those errorsProvisions multi-tier architectures: load balancers, caching, web servers, application servers, databases, and networking. Basic monitoring techniques in a dynamic environment.Infrastructure as Code: design with security, configuration management, integration, deployment, performance monitoring and tuning, automation of infrastructure.Creates automated build and release pipelines for code deploymentsPerforms other duties, as assigned. DOMAIN, KNOWLEDGE, SKILLS AND ABILITIESBanking domain experienceKnowledge of Windows and Linux is requiredExcellent research and self learning skills is requiredKnowledge of a scripting language (PowerShell, Bash etc.) is requiredExcellent time management skills are requiredKnowledge of Azure and Azure portal is requiredKnowledge of Azure Kubernetes, Azure API Management, Azure Application Gateway is an assetStrong documentation skills are requiredKnowledge of Automation Tools (ex. Azure Dev Ops, GitHub (Git Action) is requiredCapability to work independently is required\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "42_Cloud Program Manager": "Sai Sandesh,\nTetrahed\nsai@tetrahed.com\nReply to: sai@tetrahed.com\nHello Hope you're doing wellRole: Cloud Program ManagerLocation: New York, NY \u2013 3 days in the officeVisa: USC,GC,EADLocal candidates onlyMust be open to onsite interview if requested Responsibilities10-15 total years of experience5-7 plus years of cloud project management experience with the ability to manage and drive iterative technology and architecture deliveries working with cross functional teamsDefine and manage key measurements in support of architecture visionEstablish decision-making model to calculate business benefits, identify priority and phasing of architecture strategy implementationsOwn and drive iterative cadences and report progress, risks and issues via demos and metrics. Ability to use agile toolkit (e.g. Jira) Required SkillsStrong knowledge of Cloud (Azure, AWS) and experience leading cloud migrations.Experience within a large complex corporate organization or major consulting organizationHighly versed in Scrum and Kanban methodologies.Technical background in integration, development, testing, and/or infrastructure.Quick learner capable of understanding and implementing front-to-back solutions and performing in-depth analysis as required to resolve issues.Excellent relationship management, communication, teamwork, and influence skills; ability to operate at senior levels in both written and verbal communications.Ability to develop full-scale project plans including identifying and managing project dependencies and critical path.Ability to proactively manage change in project scope, identify potential issues, and devise contingencies.Ability to effectively prioritize and execute tasks in a high-pressure environment.Detail oriented, organized, self-motivated, and able to work independently as well as in a team environment.Strong familiarity with Agile project management software/tools (e.g., JIRA, etc.). Proficient with MS Office applications: Excel, MS Project, Visio, Word, and PowerPoint.Thanks and Regards,Sai SandeshTetrahed Inc.sai@tetrahed.comlinkedin.com/in/sai-sandesh-reddy-0372062a9\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "43_Hot Requirements Node.Js Backened Developer + AWS only H1B And Us Citizens only and local from  Bay Area, CA.": "Princy Jain,\nMaintec\nprincy@maintec.com\nReply to: princy@maintec.com\nHI, Greetings for the day, we are hiring Node.Js Backened Developer + AWS for one of our client, Please share H1B And Us Citizens only and local fromBay Area, CA, as soon as possible. Role \u2013 Node.js Backend Developer + AWSLocation \u2013 Bay Area, CA (Hybrid at Mountain View office) 5+ years experience developing web, software applications 5+ years of experience in mid-tier and Backend APIs with NodeJs BS/MS in computer science or equivalent work experience 5+ years experience in the Software design/architecture process Experience with the entire Software Development Life Cycle (SDLC) 5+ years experience with web services (consuming or creating) with REST or SOAP Solid communication skills: Demonstrated ability to explain complex technical issues to both technical and non-technical audiences Strong understanding of the Software design/architecture process Experience with unit testing & Test Driven Development (TDD) Experience developing, maintaining, and innovating large scale, consumer facing web or mobile applications Experience with social, mobile, cloud/SaaS, big data, or analytics Experience designing and developing distributed scalable and highly reliable applications in Cloud. Experience with AWS or equivalent services is required. Familiar with the development challenges inherent with highly scalable and available web applications Always Be Learning: Experience with open source technologies (if no practical work experience w/ Big Data, or cutting edge front-end technology\u2014you\u2019re prototyping and/or researching the up and coming technology and solutionsExperience with various, modern web framework Thanks & Regards Princy Jain Maintec Technologies Inc.Email is the best way to reach: princy@maintec.com\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "44_Azure Cloud Architect-Clayton, Missouri (Hybrid)": "Sai Supriya,\nyochana\nsupriya@yochana.com\nReply to: supriya@yochana.com\nHello ,Hope you are doing great!!!This is Sai Supriya from Yochana IT Solutions, we have an urgent requirement with one of our clients, please go through the requirement below and let me know your interest. You can forward this opportunity to your friends or colleagues; so that we can help someone who may be desperately looking for opportunities. I sincerely appreciate your time.Title : Cloud ArchitectLocation : Clayton, Missouri (Hybrid) Remote : No Role/ JD: HCL Cloud CoE (Practice) team is looking for an experienced customer-focused Azure Solution Architect with technical depth and architecture skills. In this role, you\u2019ll work closely with pre-sales, business units and engineering on some of HCL's largest and most strategic customer engagements to help identify, define, and architect solutions on Azure. Specifically, you will be part of a customer engaged team of technical PMs and engineers responsible for implementing new landing zone(s) and execute POCs and pilot migration projects. Position - Solutions Architect (Azure)Designation - Consultant/Senior Consultant/Solutions ArchitectExperience - A minimum of 8-12 years of experience in a consulting or an architecture position with a software and/or services company. Roles & ResponsibilitiesUnderstand customer's IT estate, LOB applications, IT and business priorities and success measures to design implementation architectures and cloud native solutions Collaborate with network, security, AD, backup, tools and application architects and SME's to develop enterprise grade solutions. Develop deep relationships with key customer IT decision makers.Define long term cloud strategy and mentor operations teams to implement the solutions Keeping up to date with market trends and competitive insights and maintain technical skills and knowledgeAdvocate new features and solutions to bring operational efficiency and cost reduction. Act as a subject-matter expert on Microsoft Azure and assist Sales/Pre-Sales in RFP activities.Requirements Subject matter level expertise on Azure Governance & Cost Management, Azure Network & Security, Azure Active Directory, Compute & Storage, Backup & DR, Monitoring Extensive experience in conducting design workshops, documentation of HLD (High Level Design) documents. Rich experience in Migration projects and hand-on experience with ASR/Azure MigrateGood Knowledge of Azure DevOps, ARM Templates & PowerShell scriptingExperience in PaaS services and Containers is preferred. Proven track record of building deep technical relationships with senior IT executives and growing data services in large or highly strategic accounts.Demonstrated ability to adapt to new technologies and learn quickly.Proven track record of driving decisions collaboratively.Resolving conflicts and ensuring follow through with exceptional verbal and written communication skills.Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management and developers)\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "45_Cloud Service Manager || Dallas, TX(onsite)": "khushboo,\nDigital Dhara\nkhushboo@digitaldhara.com\nReply to: khushboo@digitaldhara.com\nRole : Cloud Service ManagerLocation : Dallas, TX(onsite)We are seeking a highly skilled Cloud Architect to join our team and take charge of managing and maintaining our customer organization\u2019s cloud architecture.In this role, you will be responsible for build and operate the cloud environment of customer spanned across public clouds (AWS, Azure and GCP). Also, responsible to play the service manager role in the day-to-day cloud operations. Responsibilities: Work on day-to-day cloud operations requirement to make sure 100% availability of cloud environment.Work closely with customer cloud team to understand the new requirements and provide the solutions.Respond to technical issues in a professional and within the agreed SLA.Identify the top cloud architecture solutions to successfully meet the needs of the companyLead customer through cloud adoption and establish best practicesManage cloud ops team. Skills:Proven work experience as a Cloud Architect on public clouds (AWS, Azure and GCP)Strong communication skill to handle the P1/P2 incidentsWork experience on all foundation services on public cloud (AWS, Azure and GCP) like, compute, Storage, Networking, IAM, cloud DNS, Cloud Firewall, Disaster recovery, Cloud Databases.Work experience in ITSM tools like Service Now and well versed with ITIL processes.Multiple technical teams' coordination skills to deliver end to end service in a hybrid IT environment. Thanks & Regards,KhushbooKhushboo@digitaldhara.comPh: 609-791-0074 Ext 115\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "46_Urgent need for  Cloud Architect": "swathi,\nYochana IT solutions\nswathin@yochana.com\nReply to: swathin@yochana.com\nHi,This is Swathi from Yochana IT Solutions. i tried reaching you unfortunately went to the VM; this call is regarding the job opportunity. if you are in the job market please get back to this number (949) 577-7136 or Reach me at swathin@yochana.com Title: Cloud ArchitectLocation: Clayton, Missouri (Hybrid)Type: contractImplementation: HCL TechVisa: GC and CItizensJob description:Roles & ResponsibilitiesUnderstand customer's IT estate, LOB applications, IT and business priorities and success measures to design implementation architectures and cloud native solutions Collaborate with network, security, AD, backup, tools and application architects and SME's to develop enterprise grade solutions. Develop deep relationships with key customer IT decision makers.Define long term cloud strategy and mentor operations teams to implement the solutions Keeping up to date with market trends and competitive insights and maintain technical skills and knowledgeAdvocate new features and solutions to bring operational efficiency and cost reduction. Act as a subject-matter expert on Microsoft Azure and assist Sales/Pre-Sales in RFP activities.Requirements Subject matter level expertise on Azure Governance & Cost Management, Azure Network & Security, Azure Active Directory, Compute & Storage, Backup & DR, Monitoring Extensive experience in conducting design workshops, documentation of HLD (High Level Design) documents. Rich experience in Migration projects and hand-on experience with ASR/Azure MigrateGood Knowledge of Azure DevOps, ARM Templates & PowerShell scriptingExperience in PaaS services and Containers is preferred. Proven track record of building deep technical relationships with senior IT executives and growing data services in large or highly strategic accounts.Demonstrated ability to adapt to new technologies and learn quickly.Proven track record of driving decisions collaboratively.Resolving conflicts and ensuring follow through with exceptional verbal and written communication skills.Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management and developers) Thanks & RegardsSwathi NerallaResource SpecialistDirect: (949) 577-7136Email: swathin@yochana.com\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "47_Node.js Backend Developer + AWS :: Bay Area, CA (Hybrid at Mountain View office)": "Ekta Chaudhary,\nEpeople Technologies\nekta@epeopletech.com\nReply to: ekta@epeopletech.com\n5+ years experience developing web, software applications 5+ years of experience in mid-tier and Backend APIs with NodeJs BS/MS in computer science or equivalent work experience 5+ years experience in the Software design/architecture process Experience with the entire Software Development Life Cycle (SDLC) 5+ years experience with web services (consuming or creating) with REST or SOAP Solid communication skills: Demonstrated ability to explain complex technical issues to both technical and non-technical audiences Strong understanding of the Software design/architecture process Experience with unit testing & Test Driven Development (TDD) Experience developing, maintaining, and innovating large scale, consumer facing web or mobile applications Experience with social, mobile, cloud/SaaS, big data, or analytics Experience designing and developing distributed scalable and highly reliable applications in Cloud. Experience with AWS or equivalent services is required. Familiar with the development challenges inherent with highly scalable and available web applications Always Be Learning: Experience with open source technologies (if no practical work experience w/ Big Data, or cutting edge front-end technology\u2014you\u2019re prototyping and/or researching the up and coming technology and solutionsExperience with various, modern web framework\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "48_AWS Cloud Data bricks Architect - Remote": "Rohit,\nmsys inc\nresume@msysinc.com\nReply to: resume@msysinc.com\nTitle: AWS Cloud Data bricks Architect - RemoteLocation: RemoteLength: Long termRestriction: W2 or C2CSend resume to: rohit@msysinc.com Description:**** Webcam interview; *** Long term project *** Remote ****Responsibilities:Data Architecture Design: Design, develop, and maintain scalable data architectures on AWS to support data warehousing, analytics, and business intelligence applications.Data Warehousing: Build and manage data warehouses using AWS services such as Redshift, S3, and Glue. Ensure optimal performance, scalability, and reliability.Data bricks Integration: Utilize Data bricks for data processing, transformation, and analysis. Develop and optimize ETL/ELT pipelines using Data bricks and other AWS tools.Data Modeling: Create and maintain complex data models, including conceptual, logical, and physical models. Implement dimensional models to support analytical and reporting needs.Solution Design: Convert business requirements into technical solutions. Work with stakeholders to gather requirements, define project scope, and develop detailed technical specifications.Best Practices: Implement industry best practices for data management, data governance, and data security. Ensure compliance with relevant regulations and standards.Collaboration: Work closely with data scientists, analysts, and business stakeholders to understand data requirements and deliver solutions that meet their needs.Primary Skills:Data ModelingDimension ModelingData bricksAWS\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "49_Azure Data Architect  On C2C": "Vijay,\nYochana IT\nvijay@yochana.com\nReply to: vijay@yochana.com\nHi There, My Name is Vijay Kumar from Yochana IT. I hope you are doing great. We have an urgent requirement with one of our client for \u201cAzure Data Architect | Contract\u201d Kindly go through the requirement below and let know you interest and share me your Updated Word Document Resume at Vijay@yochana.com or Call Me at 248-306-8171. My apologies if this position is not an ideal fit, we'll keep you in mind for other suitable positions and referrals would be appreciated Role : Azure Data Architect | ContractLocation : (Durham/Raleigh, NC)-Onsite JD: o Relevant experience in data engineering tools like Azure Data pipelines , Azure Data factory, Azure Data Lake Storage, Databricks,o Delta Lake, Python, SQL Server, and experience with Azure Cloudo Strong knowledge and experience designing and implementing solutions on Databases like Hadoop, SQL Server, Oracle, Azure Synapseo Demonstrated experience in building, tuning data pipelines on Spark, Cloud native tools like Azure Data Factory, Databricks and ETL toolso Hands on Azure Data architecture experienceo Optimize Azure Synapse databaseo Performance tuning of workload and recommend adjustmento Understand the need for both batch and stream ingestion of the data from source databases like SQL Server, Oracle, MySQL and other RDBMS based databases.o Experience demonstrating and ability to talk about wide variety of data engineering tools, architectures across cloud providers and open-source tools and packages.o Experience working with business teams, dev teams and coming up with designs to deliver data solutions with best practices and standards. Thanks & Regards Vijay kumarYochana IT Solutions inc23000 Commerce MI-48335Email: Vijay@yochana.comDirect: 248-306-8171 (If I missed your Call Please E-mail me)https://www.yochana.com/Linked in- ID : https://www.linkedin.com/in/vijay-kumar-aousharala-bb13a11bb/GitHub ID : https://github.com/VijayKumaraousharala Fishbowl : https://www.fishbowlapp.com/fb/vijay-kumar-gnwe LinkedIn Group : https://www.linkedin.com/groups/12904724/ \u201cJoin the Referral Revolution of Yochana by Sharing, Earning, and Empowering!\u201d. Ask us about our rewarding referral program. Note: If you have received this mail in error or prefer not to receive such emails in the future, please reply with \u201cREMOVE\u201d in the subject line and the email id(s)\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "50_Cloud Migration and Infrastructure Lead": "Amarendra,\nsmartitframe\namarendra@smartitframe.com\nReply to: amarendra@smartitframe.com\nHello, I hope you\u2019re doing well Please check below job description and let me know if interested to apply. Job Position: Cloud Migration and Infrastructure LeadLocation: Atlanta, GA (Onsite) Job Description:Candidates should have 10-12 years in IT Infra management space along with strong experience in datacentre migration to public cloud specifically GCP.Leads the migration team on technical aspects under the guidance of the architect.Delivers an outcome of infrastructure readiness for the data centre migrationResponsible for migration/creation of x86 workloads and relative infrastructure at GCP as per move group planning by US MarketResponsible for delivering technical tasks on time, assigned during the migration phase.Responsible for creating the component sheet for each move group.Technical discussion related to infrastructure (under TCS Scope of work) with application teams along with architectResponsible to ensure installation and function of GIS Infrastructure and Security tools on all the migrated workloads in GCPResponsible for ensuring patching compliance on all the migrated workloads in GCPResponsible to ensure mandatory tags applied on all the migrated workloads in GCPResponsible to handle and resolve technical escalation under TCS scope of workSkills:NO remote , need to be in Customer office in Atlanta Strong experience in leading a technical team and public cloud migration projects.Strong understanding and hands on experience of GCP & AWS Cloud Infrastructure, preferably GCP certifiedStrong experience Windows / Active Directory AdministrationExperience in Datacentre migration (On-prem to GCP Cloud)Experience in Cloud backup and network technologiesExperience with virtualization technologies Excellent communication skillsThanks and RegardsAmarendra SrivastavaUS IT Recruiter amarendra@smartitframe.comSmart IT Frame LLC.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "51_Cloud Reliability Engineer !! Remote !! USC-GC": "Tanupriya,\nPransu tech solutions\ntanupriya@pransutechsolutions.com\nReply to: tanupriya@pransutechsolutions.com\nRemote Banking experience requiredCloud Reliability EngineerRole and ResponsibilitiesReporting to the Head of Cloud/API Engineering, the Cloud Reliability Engineer will play a critical role in driving innovation and growth for the Banking Solutions business. In this role, the candidate will have the opportunity to make a lasting impact on the company's digital transformation journey, drive customer-centric innovation and automation, and position the organization as a leader in the competitive digital banking landscape. Specifically, the Cloud Reliability Engineer will be responsible for the following:Strategize and drive the building blocks of reliability engineering as we make the transition from private to public cloud.Ensure the reliability, availability, and performance of applications and services, focusing on minimizing downtime, optimizing response times, and maintaining high availability for users.Lead incident response efforts for incidents, including identification, triage, resolution, and post-incident analysis to prevent recurrence and improve system resilience.Develop and maintain monitoring solutions and alerting mechanisms for infrastructure, application performance, and user experience metrics, enabling proactive issue detection and mitigation.Implement automation tools and processes to automate routine tasks, scale infrastructure, and ensure seamless deployments, updates, and rollbacks with minimal user impact.Conduct capacity planning, performance tuning, and resource optimization for environments, collaborating with development and operations teams to meet scalability and performance goals.Collaborate with security teams to implement security best practices, perform vulnerability assessments, and ensure compliance with security standards and regulatory requirements for applications.Manage deployment pipelines, release processes, and configuration management for app deployments, ensuring consistency, reliability, and version control across environments.Identify areas for improvement in reliability, performance, and efficiency through data analysis, root cause analysis, and trend analysis, and drive initiatives to enhance system reliability and operational efficiency.Create and maintain documentation, runbooks, and knowledge base articles for operational procedures, troubleshooting guides, and best practices, and promote knowledge sharing within the team.Develop and test disaster recovery plans, backup strategies, and failover mechanisms for app services, ensuring business continuity and data integrity in case of failures or disasters.Collaborate with development, QA, DevOps, and product teams to ensure alignment on reliability goals, performance metrics, release schedules, and incident response processes.Participate in on-call rotations and provide 24/7 support for critical incidents, troubleshoot issues, and coordinate with teams for resolution, escalation, and follow-up actions as per defined SLAs.Professional QualificationsSpecific experience in reliability engineering for a large-scale transition from private to public cloud and strategies for such.Proficient in development technologies, architectures, and platforms (web, api) to understand system complexities and performance considerations.Experience in cloud platforms (e.g., AWS, Azure, Google Cloud) and infrastructure as code (IaC) tools for managing app infrastructure and deployments.Knowledge of monitoring tools (e.g., Dynatrace, Logrocket, DataDog) and logging frameworks (e.g., ELK Stack) for real-time visibility into system health, performance metrics, and user experience.Experience in incident management, including incident response, triage, root cause analysis (RCA), and post-mortem reviews to prevent recurring issues.Strong troubleshooting skills to diagnose complex technical issues in app environments, infrastructure, networking, and performance bottlenecks.Proficiency in scripting languages (e.g., Python, Bash) and automation tools (e.g., Ansible, Terraform) for automating routine tasks, deployments, and infrastructure management.Experience in implementing continuous integration/continuous deployment (CI/CD) pipelines for apps using tools like Jenkins, GitLab CI/CD, or Azure DevOps.Expertise in setting up monitoring solutions, configuring alerts, and creating dashboards to monitor system performance, application metrics, and user experience.Familiarity with APM (Application Performance Monitoring) tools to analyze app performance, identify bottlenecks, and optimize resource utilization.Commitment to continuous learning, staying updated with industry trends, new technologies, and best practices in app reliability, performance, and operations.Adaptability to evolving requirements, technologies, and business needs, with a focus on driving continuous improvement and operational excellence.Personal CharacteristicsDemonstrates judgment and flexibility; thinks about issues and develops solutions that thoughtfully take the broader context into account - positively deals with a shifting demand for time, priorities, and the rapid change of environments.Takes an ownership approach to engineering and product outcomes.Action-oriented self-starter who can set strategy and drive execution with a \u201croll up the sleeves\u201d approach.Excellent interpersonal communication, negotiation and influencing skills to work effectively with all stakeholders (internal & external), making information-based decisions.Penchant for excellence, both personally and professionally, demonstrated by intellectual curiosity, record of accomplishment, and reputation; shows strong attention to detail and implementation of best practices with an inclination for continuous improvement.Ability to quickly establish strong credibility with employees, business partners and external resources.Embodies and delivers the firm's values and culture towards colleagues, clients, and communities:Win as one teamLead with integrity Thanks & Regards, Tanupriya Singh |Technical RecruiterPransuTech Solutions|www.pransutechsolution.comEmail:Tanupriya@pransutechsolutions.com\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "52_Urgent Need: AWS Data Architect || New York || Hybrid|| Skype": "Ashish Kumar,\nTek inspirations LLC\nashish.kumar@tekinspirations.com\nReply to: ashish.kumar@tekinspirations.com\nHi All Hope you are doing wellJob Description -Role: Data Architect- AWS (Data Visualization and Migration Specialist) Visa: CITIZEN,GC EAD,GREEN CARD,H4 EAD,L2 EAD,TN PermitLocation: NYC, NY Local with DLClient-Mizuho BankOnsite Hybrid LinkedIn id is must (Should not been created recently, at least 6 Years old in case of senior candidates)Job DetailsWe are looking for an experienced Data Visualization and Migration Specialist with a strong background in AWS QuickSight, AWS Redshift, and Amazon Q. The ideal candidate will have a proven track record of working with data visualization tools, as well as extensive experience in data migration activities, specifically moving data from on-premises data stores to Amazon Redshift.Key Responsibilities:Design, develop, and maintain interactive dashboards and reports using AWS QuickSight.Leverage Amazon Q for natural language query capabilities to enhance data accessibility and usability.Manage and optimize AWS Redshift data warehouses, ensuring data integrity and performance.Conduct data migration from on-premises data stores to AWS Redshift, including planning, execution, and validation.Collaborate with cross-functional teams to understand business requirements and translate them into effective data visualizations and reporting solutions.Implement best practices for data management, data quality, and data governance.Troubleshoot and resolve issues related to data visualization and data migration.Provide training and support to end-users on using AWS QuickSight and Amazon Q.Stay updated with the latest trends and technologies in data visualization and data migration.Required Qualifications:Bachelor\u2019s degree in Computer Science, Information Systems, Data Science, or a related field.4-5 years of experience working with data visualization tools, specifically AWS QuickSight.Strong expertise in AWS Redshift, including data warehousing and performance optimization.Experience with Amazon Q for enhancing data accessibility.Proven experience with data migration activities, particularly moving data from on-premises data stores to Amazon Redshift.Proficient in SQL and database management.Strong analytical and problem-solving skills.Excellent communication and collaboration skills.Ability to work independently and manage multiple projects simultaneously. Preferred Qualifications:AWS Certification in any of the following: AWS Certified Solutions Architect, AWS Certified Data Analytics, AWS Certified Big Data.Experience with other data visualization tools like Tableau or Power BI.Knowledge of ETL processes and tools.Experience with scripting languages such as Python or R.Regards, Ashish Kumar Senior Technical RecruiterTEK Inspirations LLC | 13573 Tabasco Cat Trail, Frisco, TX 75035.Direct: +1 469-898-0378 | Email: - ashish.kumar@tekinspirations.com\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "53_Looking for Azure DevOps Engineer need 10+yrs need locals to NY and Princeton NJ": "Austin varma,\nEminencets\naustin@eminencets.com\nReply to: austin@eminencets.com\nRole: Azure DevOps EngineerDuration: Long TermLocation: Princeton NJ or NYC office (1166 Avenue ofAmericas, New York)Hybrid: 3 days WFORoles and Responsibilities:(4-5 Years Azure experience,Expertise in deploying .NET based apps, Docker/Kubernetes/GHActions/Azure DevOps) Thanks, and regards.Austin VarmaRecruiter Eminence Technology Solutions LLCEmail: Austin@eminencets.comWebsite: www.eminencets.com\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists.",
    "54_Hiring Azure DevOps Solution Architect aat  333 S Wabhash Ave Chicago, IL 60604 (100% Day One Onsite)": "srinath,\nCalabitek INC\nsrinath@calabitek.com\nReply to: srinath@calabitek.com\nJOB DETAILS: Job Title: Azure DevOps Solution ArchitectJob Location: 333 S Wabhash Ave Chicago, IL 60604 (100% Day One Onsite)Job Type: Long TermOpenings: 1Hiring Type: Video Call any visa ( no Opt ,CPT ) JD: Software Solution Architect This role will be responsible with, architecting, implementing and supporting enterprise wide solutions, managing and maintaining the hardware and software owned by SQM. This will require supporting internal teams as well as interfacing with external teams and vendors on a regular basis. Key Responsibilities:1. Azure Cloud Migration: - Lead the planning, design, and execution of cloud migration projects to Azure. - Assess existing on-premises infrastructure, applications, and data for cloud readiness. - Develop migration strategies, including rehosting, refactoring, and rearchitecting as needed. - Execute migration tasks, including data transfer, application reconfiguration, and validation. 2. Infrastructure as Code (IaC) with Terraform: - Design and implement infrastructure using Terraform for repeatable and consistent deployment. - Develop and maintain Terraform scripts and modules for provisioning Azure resources. - Collaborate with DevOps and development teams to integrate IaC practices into CI/CD pipelines. 3. CI/CD Management: - Design, implement, and manage CI/CD pipelines using tools such as Azure DevOps, Jenkins, or GitLab. - Automate build, test, and deployment processes to enhance efficiency and reliability. - Monitor and troubleshoot CI/CD pipeline issues to ensure seamless delivery of software. 4. Enterprise Tools: - Set up and manage enterprise testing tools. - Integrate testing tools with CI/CD pipelines to enable automated testing. - Develop and enforce testing best practices and standards to ensure high-quality deliverables. - Provide support activities for the queries, issues, access, installation and configuration for supported tools - In depth knowledge and hands on experience with a broad range of industry leading commercial and open source SDLC (Agile and Waterfall), test management, test automation and CICD tools. 5. Collaboration and Documentation: - Work closely with architects, developers, and operations teams to align cloud migration efforts with business objectives. - Document cloud architectures, migration plans, Terraform scripts, and CI/CD workflows. - Provide training and support to team members on cloud and DevOps best practices. Qualifications: - 14+ Yrs of experience in IT/DevOps/Cloud Environment.- Bachelor's degree in Computer Science, Information Technology, or a related field.- Proven experience in Azure cloud migration projects.- Strong expertise in Terraform and infrastructure as code (IaC) principles.- Hands-on experience with CI/CD pipeline tools such as Azure DevOps, Jenkins, or GitLab.- Proficiency in setting up and managing enterprise testing tools like Selenium, JUnit, TestNG, and LoadRunner.- Solid understanding of cloud computing concepts, networking, and security in Azure.- Excellent problem-solving skills and attention to detail.- Strong communication and collaboration abilities. Preferred Qualifications: - Azure certifications (e.g., Microsoft Certified: Azure Solutions Architect, Azure Administrator).- Experience with other cloud platforms (AWS, Google Cloud).- Familiarity with containerization and orchestration tools like Docker and Kubernetes Preferred tool experience: - Microsoft Azure DevOps, JIRA, Bitbucket, Bamboo, ALM, Load Runner/Performance Center, JMeter, GitHub, Jenkins, Microfocus UFT/Lean FT, Selenium, Eclipse, ServiceNow, Perfecto, SeaLights, Gremlin, ToxiProxy, Chaos Monkey, Selenium Grid.\nSign-Up for your account with PROHIRES POWERHOUSE Recruiting Portal to broadcast requirements & hotlists."
}